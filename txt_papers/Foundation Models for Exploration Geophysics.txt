FoundationModelsforExplorationGeophysics
QiLiu,ZengguiChen,JianweiMa*
SchoolofEarthandSpaceSciences,InstituteforArtificialIntelligence,PekingUniversity,Beijing,China
*Correspondingemail:jwm@pku.edu.cn
AbstractRecently,largemodels,orfoundationmodels,haveexhibitedremarkableperformance,
profoundlyimpactingresearchparadigmsindiversedomains.Foundationmodels,trainedon
extensiveanddiversedatasets,provideexceptionalgeneralizationabilities,allowingfortheir
straightforwardapplicationacrossvarioususecasesanddomains.Explorationgeophysicsisthe
studyoftheEarth'ssubsurfacetofindnaturalresourcesandhelpwithenvironmentalandengineering
projects.Itusesmethodslikeanalyzingseismic,magnetic,andelectromagneticdata,whichpresents
uniquechallengesandopportunitiesforthedevelopmentofgeophysicalfoundationmodels
(GeoFMs).Thisperspectiveexploresthepotentialapplicationsandfutureresearchdirectionsof
GeoFMsinexplorationgeophysics.Wealsoreviewthedevelopmentoffoundationmodels,
includinglargelanguagemodels,largevisionmodels,andlargemultimodalmodels,aswellastheir
advancementinthefieldofgeophysics.Furthermore,wediscussthehierarchyofGeoFMsfor
explorationgeophysicsandthecriticaltechniquesemployed,providingafoundationalresearch
workflowfortheirdevelopment.Lastly,wesummarizethechallengesfacedindevelopingGeoFMs,
alongwithfuturetrendsandtheirpotentialimpactonthefield.Inconclusion,thisperspective
providesacomprehensiveoverviewofthedevelopment,hierarchy,applications,development
workflow,andchallengesoffoundationmodels,highlightingtheirtransformativepotentialin
advancingexplorationgeophysics.
1Introduction
Asartificialintelligenceevolvesfromrule-basedsystemstotheeraofmachinelearning,data-
drivendeeplearningmethodshaveemergedasasignificantadvancement.Thesemethodsutilize
neuralnetworkstouncovercomplexpatternswithindataacrossawiderangeofapplications.With
therapidgrowthofdatavolumesandcontinuousadvancementsincomputationalresources,deep
learning-basedfoundationmodelshavegainedsignificantattention.Foundationmodelsarelarge-
scale,pre-trainedmodelsdevelopedonvastanddiversedatasets,oftenleveragingself-supervisedor
unsupervisedlearningtechniques.Theaimoffoundationmodelsistocreateaflexibleandadaptable
basethatcansupportavarietyoftasksandapplications.Inrecentyears,theemergenceoffoundation
modelshasachievedgreatsuccessinvariousfields,includingnaturallanguageprocessingmodels
representedbyChatGPT1,imagesegmentationmodelssuchasSegmentAnythingModel2(SAM),
andvideoprocessingmodelsrepresentedbySora3,amongothers.Trainedonmassivedatasetsand
withavastnumberofmodelparameters,thesemodelspushtheboundariesofdeeplearning,
demonstratingitsremarkablepotential.Theexceptionalperformanceoffoundationmodelshas
profoundlyinfluencedtheresearchparadigmsinvariousfields,suchasgeoscience62,63,chemistry4,5,
biology6,finance7,8,medicine9,andremotesensing10-12,amongothers.However,theapplicationand
developmentoffoundationmodelsinexplorationgeophysicsarestillinaninitialstage.
GeophysicsisascientificdisciplinethatinvestigatesandanalyzestheEarth'sstructuresand
statesusingphysicalprinciplesandmultimodalgeophysicaldata.Explorationgeophysicsutilizes
geophysicaltechniquesanddatatostudytheEarth'ssubsurfacestructure,aidinginthediscoveryof
naturalresourcessuchasoil,gas,andminerals.Sub-disciplineslikeremotesensingandseismology
alsocontributevaluableinsights.Remotesensingusessatelliteimagestostudysurfaceconditions
andmonitorenvironmentalchanges,whileseismologyfocusesonearthquakesandprovidesinsights
intotheEarth'sinternalcompositionanddynamics.Thesesub-disciplinescollectivelyoffera
comprehensiveunderstandingoftheEarth'ssubsurfaceandsurfacestates.Theprocedureof
geophysicsmainlyincludesthreestages:dataacquisition(multimodalgeophysicaldata,suchas
seismicdata,remotesensingimages,gravitydata,atmosphericdata,etc.),dataprocessing(multiple
tasks,suchasfirst-arrivalpicking,interpolation,anddenoising),anddatainterpretation(seismic
imaging,weatherforecasting,earthquakedetection,andsoon).Thedataprocessingstagehasthe
followingfeatures:(1)largeamountsofdata;(2)multimodaldata;(3)multipletasks.The
interpretationstagesignificantlyreliesonhumananalysisandexperience.Theextensivemultimodal
datasetsprovideafoundationfortrainingandfine-tuningGeoFMs,whilethecomplex,multi-task
natureofthefieldhighlightsthepotentialforGeoFMstosignificantlyenhanceexploration
geophysics.
Figure1Researchparadigmshiftinexplorationgeophysics,thetransitionfromtraditionalmethods
todeeplearningmethodsandfoundationmodelswithcorrespondingfeatures.
Overthepastdecade,therapiddevelopmentofdeeplearningmethodshashadaprofound
impactontheresearchparadigminexplorationgeophysics,whichhasshiftedfromtraditional
methodstodeeplearning-baseddata-drivenapproaches13,andfurthertofoundationmodels,as
showninFigure1.Traditionalmethodsareusuallymodel-drivenandfollowspecificassumptions.
Moreover,theyareintricatelydependentontheexperienceofexperts.Forexample,thelinearity
assumptionpresumesthattheseismiceventsexhibitlinearityinsmallwindows14,whiletransform-
domain-basedmethodsassumethatthedataaresparse15orlow-rankaftertransformations16,likethe
Fourier17,Curvelet18,andRadon19transforms.Thesetraditionalmethodsareeffectiveintheseismic
dataprocessingstage.However,whenfacedwithcomplexfielddata,theymaynotbeabletoobtain
reasonabledenoisingorinterpolationresultsduetotheinvalidassumptions.Withtheexponential
growthofdataacrossvariousdomains,data-drivendeeplearningmethodshaveemergedasafocal
pointofresearch.Deeplearningmethodshavebeenutilizedinvariousfieldsofexploration
geophysics,suchasfirst-arrivalpicking20,interpolation21,inversion22,etc.Reviewarticlesabout
deeplearningingeophysicshaverecentlybeenpublished13,23,providingadetailedaccountofthe
applicationofdeeplearningmethodsingeophysics.Nonetheless,thecurrentdeeplearningmethods
ingeophysicsaremostlybasedonthelimitedparametervolumesandtrainingdata,whichlimitsthe
generalizationofthemodelandtherebyrestrictstheapplicationofdeeplearning-basedmethodsin
theexplorationindustry.Inlightofthedevelopmentsoffoundationmodels,theselimitationsare
graduallybeingalleviated.GeoFMs,trainedonalargeamountofmultimodalgeophysicaldata,
demonstratestronggeneralizationcapabilitiesacrossvariousgeophysicaldownstreamtasks,
assistingresearchersinconductingacademicstudiesandexplorationoperationsinthefieldof
geophysics.
Thesuccessoffoundationmodelsacrossvariousfieldshasdemonstratedtheimmensepotential
ofdeeplearningmethods,whichareboundtobringprofoundchangestotheparadigmof
geophysicalresearch.Thispaperaimstoofferanoverviewofrecentfoundationmodelsresearchin
explorationgeophysics,examinehowtheeraoffoundationmodelshasimpactedtheparadigmof
geophysicalresearch,andexplorepotentialresearchdirectionsforGeoFMs.Themaincontributions
ofthispaperaresummarizedasfollows:
IntroductiontoFoundationModelsandTheirApplicationsinGeophysics:Thispaper
introducestheconceptoffoundationmodels,includinglargelanguagemodels,largevision
models,andlargemultimodalmodels.Itreviewsthedevelopmentofthesemodelsand
explorestheirapplicationswithinexplorationgeophysics,emphasizingtheirpotentialto
transformthefield.Thepaperalsoprovidesabriefoverviewoftheuseoffoundation
modelsinrelatedgeophysicalsub-disciplines,illustratingtheirbroaderrelevanceto
geophysics.
HierarchyofGeoFMs:ThepaperpresentsthehierarchyofGeoFMsintofourdistinct
levels:task-specificmodel,modality-specificmodel,multimodalmodel,geophysicalagent
andcopilot.Wedetailthespecificcharacteristicsandapplicationsofeachlevel,examine
theinterrelationshipsbetweentheselevels,andhighlighttheirinteractionand
complementarityinthecontextofgeophysicalapplications.
ProposedGeneralizedWorkflowforGeoFMDevelopment:Weproposeageneralized
workflowforthedevelopmentofgeophysicalfoundationmodels,whichcomprisesfour
stages:datapreparation,pretraining,multimodalalignment,anddownstreamtask
adaptation.Wediscussthekeytechniquesusedateachstageandprovidepractical
examplestoillustratetheapplicationofthisworkflowinthedevelopmentofGeoFMs.
ApplicationsofGeoFMsinExplorationGeophysics:Thepotentialapplicationsof
GeoFMsinvariousareasofexplorationgeophysics,includingdataprocessing,geophysical
imaging,andinversion,arediscussed.Thepaperusesfirst-arrivalpickingasacasestudyto
illustratethespecificapplicationofGeoFMsinseismicdataanalysis.Additionally,it
addressesthedevelopmentstrategiesfordifferenttasksandthechallengesassociatedwith
applyingGeoFMstothesetasks.
ChallengesandFutureDirectionsforGeoFMDevelopment:Thepaperoutlinesthekey
challengesthatGeoFMsarelikelytoencounterduringtheirdevelopmentanddeployment.
ItalsooffersanoutlookonfuturetrendsandpotentialapplicationsofGeoFMs,
emphasizingthetransformativepotentialofthesemodelsinadvancingexploration
geophysics.
Thestructureofthepaperisorganizedasfollows:Section2introducesthebackgroundof
foundationmodels.Section3reviewsthedevelopmentandapplicationsoffoundationmodels
withinexplorationgeophysicsandotherrelatedfields.InSection4,GeoFMsareclassifiedinto
fourlevels,withadiscussionoftheinterrelationshipsbetweentheselevels.Section4also
presentsageneralizedworkflowforthedevelopmentofGeoFMs,outliningthekeystagesand
techniquesinvolved.Section5examinestheapplicationsofGeoFMsacrossvariousareasof
explorationgeophysics,illustratedthroughacasestudyonfirst-arrivalpicking.Section6
discussesthechallengesfacedbyGeoFMsandprovidesanoutlookonfuturetrends.Finally,
Section7concludesthepaperbysummarizingitskeycontributions.
2TheBackgroundofFoundationModels
Byofferinghighlygeneralizablecapabilitiesthatcanadaptacrossawiderangeoftasks,the
developmentoffoundationmodelshasreshapednumerousfields.Thissectionintroducesthe
backgroundoffoundationmodels,focusingonthreekeycategories:LargeLanguageModels
(LLMs),LargeVisionModels(LVMs),andLargeMultimodalModels(LMMs).Eachofthese
categorieshasdemonstratedexceptionalpotentialintheirrespectivedomainsandcollectively
contributestoadvancementsinartificialintelligence.
2.1LargeLanguageModels
LLMsarepre-trainedonvastamountsoftextdata24,25andarecapableofhandlinganytext-
formattedtaskwithoutthenecessityoftask-specificfine-tuning.Theremarkablezero-shot
generalizationcapabilityofLLMsisattributedtothein-contextlearningparadigm26,whichallows
LLMstorecognizevariouspatternsinnaturallanguageandlearnpromptsthroughnext-token
predictioninautoregressivetraining.
TheintroductionoftheTransformerframework27hasrevolutionizedthedevelopmentofLLMs.
Thesemodels,builtupontheself-attentionmechanism,arecapableofcapturinglong-distance
dependenceintextandenableparalleltrainingwithlargeparameters,therebylayingthe
methodologicalfoundationforLLMstraining.LLMsrequireextensivetextdatacollectedfrom
varioussourcesandaretrainedonthousandsofGPUsorTPUs,withthescaleoftrainingreaching
billionsofparameters.NotableexamplesincludetheGPT1seriesdevelopedbyOpenAI,which
utilizesadecoder-onlyTransformerarchitectureandincorporatesreinforcementlearningfrom
humanfeedback28tofine-tunemodelresponses.TheGPTmodelshavesetnewbenchmarksfor
naturallanguageunderstandingandgenerationtasks.Google’sPaLMseries29hasachievedefficient
trainingofsuper-largeparametersonTPUswithbreakthroughperformanceinmanydownstream
tasks.MetaAIreleasedtheLLaMAseries30andopen-sourcedthemodelparameters,providinga
foundationfortheresearchofLLMs.Recently,theClaude3series31launchedbyAnthropichas
madebreakthroughprogressintexttaskswithultra-longsequences.Inaddition,thereareotherhigh-
performanceLLMssuchasLaMDA32,GLM33,OPT34,andChinchilla35.TheseLLMshaveachieved
inspiringresultsinnaturallanguageprocessingtasks,graduallyrevolutionizingtheworkpatternsof
professionalsacrossvariousfields,includinggeoscience36,121,remotesensing36,chemistry5,37,
medicine38-40,andothers.Inthefieldofgeophysics,LLMswithgeophysicalknowledgecanserveas
thefoundationfordevelopinggeophysicalartificialintelligence,leveragingmultimodalalignmentto
accessvariousGeoFMs.
2.2LargeVisionModels
MostLVMsareprimarilybuiltuponVisionTransformer(ViT)41orconvolutionalneural
network(CNN)architecturesandarepretrainedonlarge-scaleimageandvideodatasets.These
modelshaveachievedstate-of-the-artresultsinvariousdownstreamtasks.Inthesegmentationtask,
SAM2hasattractedwidespreadattentionduetoitsoutstandingsegmentationperformanceand
remarkablegeneralizationability.Furthermore,otherfieldscanutilizeitfordatasegmentation,such
asidentifyingtheinitialarrivalsinseismicdatasets.Anothernotabledevelopmentistheimage
restorationfoundationmodelnamedSUPIR42,whichhasachievedadvancedresultsinvarioustypes
ofimagerestorationtasks.Inaddition,multimodalLVMshavemadesignificantbreakthroughsin
text-to-imagegenerationandtext-controlledimageediting,suchasthecontrastivelanguage-image
pre-training(CLIP)model43,DALL-E442,GoogleImagen45,andStableDiffusion46.
Despitetheimpressiveachievements,mostcurrentLVMsareeithertrainedforsinglevisual
tasksorareheavilydependentonLLMsforguidance.Asaresult,thedevelopmentofpureLVMs
hasemergedasarecentareaofinterest47.ThesuccessofLLMsislargelyduetothein-context
learning26paradigm,whichenablesthemtocompleteanytext-formattedtasksthroughprompting.
However,theabsenceofthein-contextlearningparadigminLVMshinderstheflexiblespecification
oflanguagetasksinvisualpromptsasinLLMs47.Recently,researchershavestartedtoexplorenew
trainingparadigmsforLVMs,withtheobjectiveofdevelopinguniversalLVMscapableoftacklinga
varietyofvisualtasks.Baietal.48(2023)definedacommonformat,“visualsentences”,toenablethe
specificationofvisualtasks,andconstructedalarge-scaledatasettosupporttheirwork.Specifically,
“visualsentences”articulatevisualtasksthroughsequencesofimages,withthemodelbeingcapable
ofpredictingthenextimagebylearningpatternswithintheprovidedimagesequence.Guoetal.49
(2024)proposedamethodoftokenizingtheimagesfirst,followedbyautoregressivetrainingonthe
tokens.TheseeffortsaimtoadvancethedevelopmentofgeneralLVMs,providingvaluableinsights
fortheevolutionoffoundationmodelsinotherdisciplines50,51.Suchadvancementsarecrucialforthe
applicabilityofLVMstomorespecializeddomains,includinggeophysics,wherecomplexseismic
datainterpretationsareoftenrequired.
2.3LargeMultimodalModels
Largemultimodalmodels(LMMs)representasignificantadvancementinartificialintelligence
byintegratinginformationfrommultipledatamodalities,suchastext,images,audio,andothers.
Thisintegrationfacilitatesamoreprofoundandnuancedcomprehensionoftasksacrossvarious
areas.Bycomprehendingtheintricateinteractionsamongmanydatamodalities,LMMsprovide
enhancedadaptabilityrelativetosingle-modalitymodels.
Thedevelopmentofmultimodalfoundationmodels51hasseennotablecontributionsthat
significantlyenhancethecapabilitiesofartificialintelligenceinunderstandingandgeneratingacross
multipledatatypes.AprominentexampleistheCLIP43modeldevelopedbyOpenAI,whichlearns
visualrepresentationsfromnaturallanguagedescriptions,enablingzero-shotimageclassification
andotherdownstreamtaskswithimpressiveaccuracy.CLIPutilizesacontrastivelearning
frameworktoalignimageandtextrepresentations,effectivelybridgingthegapbetweenvisualand
linguisticinformation.Flamingo52byDeepMindhavefurtheradvancedtheintegrationofvisionand
language,allowingAItoperformvisualquestionanswering,imagecaptioning,andeveninteractive
conversationsinvolvingvisualcontent.ThearchitectureofFlamingoeffectivelyintegratesboth
imageandtextstreams,underscoringthegrowingtrendofdevelopingAIsystemsthataremore
dynamicandversatile.Inaddition,Meta'sImageBind53representsagroundbreakingsteptowardtrue
multimodalintegrationbylearningjointembeddingsacrosssixdifferentmodalities,including
images,text,audio,depth,thermal,andinertialmeasurements.ImageBind'sapproachaimstocreate
asharedsemanticspacethatcansimultaneouslyunderstandandgeneratefrommultipledatatypes.
DALL-E54,GoogleImagen55,GPT-4o1,andBlip-257areallnotablemultimodalmodels,
demonstratingthepowerofintegratinglanguageandvisionincreativeandanalyticalapplications.
Theabilityofmultimodalmodelstounderstandcontextandperformcomplex,cross-domaintasks
makesthemparticularlyusefulingeophysics,wheredataoftencomesinmultipleforms(e.g.,
seismicshotgathers,geologicalimages,welllogs,andtextualreports).
3FoundationModelsinGeophysics
Inrecentyears,geophysicistshaveincreasinglyfocusedonthedevelopmentoffoundation
modelsingeophysics,leadingtosignificantadvancementsacrossvarioussubfieldsbyleveraging
multimodalgeophysicaldata.Thesefoundationmodelshaveachievedsubstantialprogress,
transformingmultipleareasofgeophysicalresearchandapplications.Figure2providesanoverview
ofGeoFMsingeophysics,illustratinghowthesemodelsexcelatvariousdownstreamtasksandare
applicableacrossmultiplesubfields.Below,weprimarilyfocusontheadvancementsofGeoFMsin
explorationgeophysicswhilealsosummarizingkeydevelopmentsinothergeophysicaldomains.
Figure2OverviewofGeoFMsingeophysics.(a)GeoFMsaretrainedonmultimodalgeophysical
datatoacquireknowledgeinthegeophysicaldomain.(b)Varioustasksinthefieldofgeophysics
canbeeffectivelyaccomplishedbyinteractingwithgeophysicalLLMsandinvokingdifferent
GeoFMs.(c)ApplicationsofGeoFMsinthefieldofgeophysics.
3.1ExplorationGeophysics
Explorationgeophysicsfocusesoninvestigatingsubsurfacestructurestosupportnatural
resourceexploration.Unlikeareassuchasmedicine,remotesensing,andotherdisciplines,the
applicationanddevelopmentofGeoFMsinexplorationgeophysicsarestillinaninitialstage.The
relevantfoundationmodelresearchinexplorationgeophysicsissummarizedinTable1.Currently,
interpretivetasksaretheprimaryfocusoffoundationmodeldevelopmentinexplorationgeophysics.
Incontrast,thelackoflarge,high-qualitydatasetshinderstasksrelatedtodataprocessing,limiting
progressinthisarea.Theseismicimagingdomain,ontheotherhand,remainsheavilyrelianton
physicalconstraints,whichcomplicatestheintegrationoffoundationmodels.Asaresult,related
workinthesetwoareasisstillrelativelysparsecomparedtointerpretivetasks.
Shengetal.77(2023)developedthefirstseismicfoundationmodel(SFM)basedonmigrated
seismicdatausingaMaskedAutoencoder83(MAE)architectureforpre-training,achievingstate-of-
the-artresultsinvariousseismicdownstreamtasks,whichmarksasignificantexplorationin
geophysicalresearchintheeraoffoundationmodels.Hanetal.58(2024)introducedamulti-
attributesmaskingcontrastivelearning(MAMCL)approachusingmultimodalgeophysicaldata,
achievingexcellentperformanceinexplainableseismicfaciesanalysis.Inthispaper,wepresenta
novelapproachbyapplyingtheexistingfoundationmodelSAMtothetaskoffirst-arrivalpickingin
seismicdata.Subsequently,Guoetal.57(2024)proposedfine-tuninglargevisionmodelsusing
multimodalgeophysicaldatatoaccomplishtaskssuchasgeophysicaldataanalysis.Kumaretal.
(2024)developedaViT-based41foundationmodelfornumericalsimulationstudiesintheoilandgas
industry.Numericalsimulations,whicharecomputationallyintensivewithlongturnaroundtimes,
canbenefitsignificantlyfromthisapproach.Additionally,Liuetal.67(2024)provideda
comprehensivereviewofthedevelopmentandapplicationsoflargemodeltechnologyintheoiland
gassector.
Therapiddevelopmentoffoundationmodelsinexplorationgeophysicshasopenedupnew
avenuesforadvanceddataanalysisandsubsurfaceexploration.Fromseismicanalysistomultimodal
geophysicaldatainterpretation,GeoFMsareprovingtobehighlyeffectiveinaddressingcomplex
challenges.Whilemuchoftheresearchisstillinitsearlystages,thedemonstratedsuccessofthese
modelsinavarietyoftaskssuggestsapromisingfuture.
Reference DataType Methods KeyFeatures
SFM[86]MigratedSeismic
DataMAEPretrainingFoundationmodel,canbe
adaptedondownstreamtasks
GeoFMs(ours) ShotGather SAM First-arrivalpicking
CDFMA[57] Multimodal Fine-tuning Geophysicaldataanalysis
MAMCL[58] SeismicFaciesContrastive
LearningSeismicfaciesanalysis
RockGPT[59] DigitalRocksGenerative
PretrainingRandomreconstructionon
digitalrocksdata
Kumaretal.
[60]ReservoirSimulation
ModelsViTPretraining Oilreservoirforecasting
3.2RemoteSensing
Remotesensing,whichemployssensorsonsatellitesoraerialplatforms,isacrucialtoolfor
collectinggeophysicaldata,facilitatingthemonitoringandanalysisoftheEarth'ssurfaceand
environment.Remotesensingdataprimarilyconsistsofvarioustypesofimagedata,including
syntheticapertureradar(SAR)images,thermalinfraredimages,opticalimages,amongothers.
Currently,remotesensingstandsasthemostdevelopeddomainfortheapplicationoffoundation
modelswithingeophysics.Manytasksinremotesensingbearsimilaritiestothoseinnatural
languageprocessing(NLP)andcomputervision(CV),contributingtothisprogress.Taskssuchas
imageclassification,objectdetection,andsegmentationinremotesensingareconceptually
analogoustothoseinCV,whilespatiotemporaldataanalysisinremotesensingsharessimilarities
withNLPtasksinvolvingsequentialdata.Therefore,byfine-tuning,wecaneasilyadaptexisting
largepre-trainedmodelsfromNLPandCVtoremotesensingapplications.
Inrecentyears,anumberofcomprehensivereviewshaveemerged,highlightingthegrowing
interestinthedevelopmentandapplicationoffoundationmodelsinremotesensing.Dataetal.64
(2023)providedadetailedreviewoftheevolutionofEarthobservationtechniques,focusingon
remotesensingasakeymethod.Thisworkhighlightstheincreasingchallengesposedbythe
growingvolumeofmultimodalremotesensingdataandemphasizestheneedforadvancedAI
techniques,suchasfoundationmodels,toeffectivelyextractandutilizethiswealthofinformation.
Luetal.65(2023)exploredtheroleofself-supervisedlearninginenhancingmodelperformancefor
taskslikesceneclassificationandobjectdetectioninremotesensing.Theirstudyunderlineshow
self-supervisedlearningapproacheshavebeeninstrumentalinadvancingfoundationalmodelsby
providingmoreeffectivepre-trainingstrategiesthatleveragelargeamountsofunlabeleddata.Jiaoet
al.66(2023)conductedasurveyoffoundationmodelsinremotesensing,evaluatingarangeof
modelsacrossmultipledatasets.Theirworkconfirmedthestrongperformanceoffoundationmodels
inthisfield,particularlyintaskssuchasfeatureextraction,dataclassification,andhighlighted
importantdistinctionsinmodeleffectivenessfordifferenttypesofremotesensingdata.
3.3Seismology
Seismologyisthescientificstudyofearthquakesandthepropagationofelasticwavesthrough
theEarthorotherplanet-likebodies.Thisfieldinvolvesanalyzingandinterpretingseismicdata
collectedfromseismographsandotherinstruments,therebyenhancingtheunderstandingofthe
Earth’sinternalstructure.Recentadvancementsindeeplearninghavesignificantlyenhancedthe
fieldofseismology,withthesemethodsnowbeingbroadlyappliedacrossadiverserangeoftasks
withinthediscipline.Thesetasksinclude,butarenotlimitedtophasepicking56-58,first-motion
polarityclassification56,59,earthquakedetection58,60,61,eventlocation62,63,andearthquakeprediction64-
66.However,thesemethodsareoftentrainedonspecifictasksusinglimiteddatasets,whichrestricts
theirwideapplicationduetotheirlimitedgeneralizationability.
Inspiredbythesuccessoffoundationmodelsinvariousfields,researchershavebegunto
exploretheuseofvastamountsofseismicdatatotrainGeoFMsinthefieldofseismology.
SeisCLIP67isafoundationmodelinthefieldofseismology,utilizingcontrastlearningon
multimodaldataforpretraining.Thisfoundationmodelcanbeappliedtoavarietyofdownstream
tasks,suchaseventclassification,localization,andfocalmechanismanalysistasksthroughfine-
tuningwithsmalldatasets.Lietal.68(2024)introducedSeismogramTransformer(SeisT),a
foundationmodeldesignedforvariousearthquakemonitoringtasks,includingearthquakedetection,
seismicphasepicking,first-motionpolarityclassification,andsoon.Thismodelwastrainedonthe
DiTingdataset97andevaluatedforitsgeneralizationabilityonthePNWdataset98.Bothdatasets
encompassasignificantnumberofseismiceventsandcorrespondinglabelssuchasarrivaltimes,
magnitude,andfirst-motionpolarity.Additionally,SeisLM69(2024)introducesafoundationalmodel
foranalyzingseismicwaveforms.SeisLMlearnsgeneralwaveformpatterns,enablingstrong
performanceintaskssuchaseventdetection,phase-picking,onsettimeregression,andforeshock–
aftershockclassification.Thismodelfurtherdemonstratesthepotentialoffoundationmodelsin
seismology,showingpromiseinmultiplefundamentaltasksrelatedtoearthquakemonitoringand
analysis.TheseGeoFMshavedemonstratedsubstantialpotentialtoaddressdifferentseismological
tasks,significantlyimpactingtheresearchparadigmwithinthefieldofseismology.
3.4AtmosphericScience
Atmosphericscienceisascientificdisciplinededicatedtothestudyandunderstandingofthe
Earth’satmosphere,includingaspectssuchasweatherandclimateandtheirinteractionswithother
systemsonEarth.Thisfieldiscrucialforweatherforecasting,climateprediction,andunderstanding
changesinourenvironmentduetonaturalandhuman-madefactors.Overthepastdecade,weather
forecastinghasconsistentlyreliedonnumericalweatherpredictionmethods69,70,whichsimulate
transitionsofatmosphericstatesbasedonpartialdifferentialequations.
Recently,deeplearning-basedweatherpredictionmethods71,72haveemergedaspromisingtools
foracceleratingweatherforecasting.However,thesemethods,trainedwithlimiteddata,donot
achievetheaccuracyofconventionalnumericalweatherpredictiontechniques.Toaddressthese
limitations,severalGeoFMshavebeendevelopedinthefieldofatmosphericscience.Trainedwith
vastamountsofdata,theseGeoFMshaveexhibitedoutstandingperformanceinbothprediction
speedandaccuracy.Zhuetal.70(2023)exploredthepotentialoffoundationmodelsinearthand
climatesciences,identifyingelevenkeyfeaturesneededforanoptimalearthfoundationmodel.
TheirworkprovidesimportantguidelinesforthefuturedevelopmentofGeoFMs,highlighting
aspectssuchasdatadiversity,modelscalability,andphysicalinterpretability.Similarly,Zhanget
al.71(2023)evaluatedthepotentialoffoundationmodelsinatmosphericscience,examiningtheir
performanceacrosstasksincludingclimatedataprocessing,physicaldiagnosis,forecasting,and
adaptation.Theirfindingsillustratethediverseapplicationsoffoundationmodelsinatmospheric
research,emphasizingtheirabilitytoenhanceaccuracyandefficiencycomparedtotraditional
methods.Zhangetal.73(2023)developedNowcastNetusinganend-to-endoptimizationarchitecture
thatintegratesphysical-evolutionschemestogeneratehigh-resolution,physicallyplausiblenowcasts.
Bietal.74(2023)presentedPangu-Weather,aGeoFMdesignedforrapidandaccurateweather
prediction,whichwastrainedon39yearsofglobalweatherdata.Thismodeldemonstratessuperior
performancecomparedtotheleadingnumericalweatherpredictionmodelofthatperiod,thereby
highlightingthetransformativepotentialofGeoFMsinatmosphericscience.
3.5Oceanography
Oceanography,oroceanscience,investigatestheintricaciesoftheoceansthatcoverover70%
oftheEarth’ssurface.Thisfieldisvitalforunderstandingmarinelifeandbiodiversity,assessingthe
ocean’sroleinclimateregulation,andexaminingtheirimpactonglobaleconomies.Inspiredbythe
remarkablesuccessoffoundationmodelsingeneraldomains,oceanographershavebeguntoexplore
thepotentialofGeoFMsinthefieldofoceanography.
Bietal.75(2024)introducedOceanGPT,thefirstoceanographicLLMpre-trainedforvarious
oceansciencetasks.Togetaroundtheproblemsofgettingoceandata,theDoinstructdomain
constructionframeworkwassuggested.Thisframeworkletsmultipleagentsworktogethertobuild
anoceaninstructiondataset.Xiongetal.76(2023)presentedAI-GOMS,aGeoFMemployingthe
Fourier-basedmaskedautoencoderarchitecture,whichwasdesignedforpredictingoceanvariables
overa30-dayperiod.Inadditiontotheselanguage-basedmodels,MarineInst(2024)wasintroduced
asafoundationalmodelspecificallydesignedformarinevisualanalysis.MarineInstprovides
instancemasksandcaptionsformarineobjects,addressingtheuniquechallengesinherentinmarine
imageanalysis.Itdemonstratesstronggeneralizationacrossvariousdownstreamvisualtasks,
makingitavaluabletoolfortaskssuchasidentifyingmarinespecies,mappingoceanhabitats,and
monitoringenvironmentalchanges.
4HierarchyandDevelopmentWorkflowofGeoFMs
ThissectionprovidesacomprehensiveexplorationofGeoFMs,focusingonboththeirhierarchy
andageneralizedworkflowfortheirdevelopment.ThehierarchyofGeoFMsisdividedintofour
distinctlevels:task-specificmodels,modality-specificmodels,multimodalmodels,geophysical
agentandcopilot.Thisdivisionprovidesinsightsintotheuniquecharacteristicsandapplicationsof
eachtype,aswellashowtheyinteracttoadvancegeophysicalresearch.Furthermore,ageneralized
workflowfordevelopingGeoFMsisintroduced,detailingthefourkeystages:datapreparation,
pretraining,multimodalalignment,andtask-specificadaptation.Eachstageisaccompaniedbya
discussionofthecoretechniquesemployed,alongwithapracticalexampletodemonstratetheir
implementation.Thisstructuredapproachprovidesaroadmapforadvancingthedevelopmentand
applicationofGeoFMsinthefieldofexplorationgeophysics.
(a)HierarchyofGeoFMs
Figure3ThehierarchyofGeoFMs,fromgeophysicalagentandcopilottodatabasis.
4.1HierarchyofGeoFMs
Figure3illustratesthehierarchyofGeoFMs,organizedfromthehighesttolowestlevelof
intelligence:Geophysicalagentandcopilot,multimodalmodel,modality-specificmodel,task-
specificmodel,anddatabasis.Thissubsectionprovidesadetailedoverviewofeachhierarchylevel,
discussingtheiruniquecharacteristicsandthewaysinwhichtheyinteractandcomplementeach
otheringeophysicalresearch.
4.1.1GeophysicalAgentandCopilot
Geophysicalagentandcopilotrepresentthehighestlevelofintelligenceinthehierarchyof
GeoFMs.TheyareanintegrationofdifferentlevelsofGeoFMs,combiningvariouscapabilitiesto
achieveadvancedintelligenceandadaptability.Geophysicistscanusethesemodelsasintelligent
assistantsor"co-pilots"whocannotonlyunderstandandanalyzedata,butalsoprovidesupportfora
widerangeofgeophysicaltasks.
Thegeophysicalagentisanautonomoussystem77designedtounderstanduserinstructionsand
analyzediversegeophysicaldata,enablingautomatedworkflowdesignanddecision-makingfor
explorationtasks.Forinstance,thegeophysicalagentcanunderstanddifferenttypesofseismicdata
throughintegratedmultimodalGeoFMs,createautomatedworkflows,andusetask-specificGeoFMs
orrelevantsoftwareAPIstoprocessandinterpretseismicdata,whichhelpsguideexploration
operations.Thistypeofmodelaimstomimicexpert-levelunderstanding,includingaspectssuchas
patternrecognition,decision-makingheuristics,andcontextualanalysis,therebyreducingthe
relianceondomain-specificknowledgefromexpertsforroutineseismictasks,andenablingnew
insightsintocomplexgeophysicalchallenges.
Inthefieldofexplorationgeophysics,traditionalstandardizedworkflowsandprocessing
interpretationsoftwarearealreadyquitemature,buttheirusageandoperationoftenrequire
specializedknowledgeandextensiveexperience,whichcreatesaneedforanassistingtool.The
geophysicalcopilotaddressesthisneedbyservingasanessentialassistant78thatintegratesuserinput
withadvanceddataanalysiscapabilities.Thedesignofthegeophysicalcopilotallowsitto
comprehendvariousexplorationdatamodalities,includingwelllogs,shotgathers,andseismic
images,andaidsgeophysicistsincreatingworkflowsspecifictotheirtasks.Byincorporatingtask-
specificGeoFMsorusingrelevantsoftwareAPIs,thegeophysicalcopilothelpsvalidatehypotheses,
generateinsights,andoptimizedataprocessingandinterpretationtasks.Thisinteractiveapproach
ensuresthatgeophysicistsretaincontroloverdecision-makingwhilegainingthebenefitofenhanced
supportandoperationalefficiency.
4.1.2GeophysicalMultimodalModels
GeophysicalmultimodalmodelsrepresentthenextlevelinthehierarchyofGeoFMs,providing
anintegratedapproachtounderstandinggeophysicaldatabycombiningdifferentdatamodalities.
Thesemodelsenhancetheabilitytoidentifypatternsandrelationshipsthatmaynotbeevidentwhen
eachtypeofdataisanalyzedindependently,offeringacohesiveunderstandingofcomplex
geophysicaltasks.Geophysicalmultimodalmodelsarebuiltuponmodality-specificmodels,
leveragingtheiroutputstoalignandintegrateinformationfromdifferentdatatypes.
Theprimaryadvantageofmultimodalmodelsliesintheirabilitytoextractcomplementary
informationfromdiversemodalities,whichiscrucialforcomplexgeophysicalprocessingand
interpretations.Forexample,inexplorationgeophysics,combiningseismicdatawith
electromagneticmeasurementsenhancestheaccuracyofsubsurfaceimagingandresourceestimation.
Furthermore,thesemodelsserveasabridgebetweenmodality-specificmodelsandhigher-level
GeoFMsbyprovidingenriched,unifiedlatentdatarepresentationsthatcanbeusedformore
comprehensiveanalysis.Multimodalmodeltrainingalwaysstartswithunimodalpretraining,where
eachmodality-specificmodellearnsindependently,followedbyamultimodalalignment79phasethat
integratestheseindividualrepresentationsintoacohesivewhole.Byutilizingsharedembedding
spacesandcontrastivelearning,thesemodelsensurethatinformationfromdifferentsourcesis
effectivelyharmonized,allowingforcomprehensiveanalysisacrossdatatypes.Bydoingso,theylay
thegroundworkfordevelopinggeophysicalagentandcopilotthatcanmakemoreinformed
decisionsbasedonaholisticunderstandingofdifferentgeophysicaldata.
4.1.3Modality-specificModels
Modality-specificmodelsrepresentafundamentallevelinthehierarchyofGeoFMs,focusing
ontherepresentationlearningofgeophysicaldatafromasinglemodality.Thesemodelsare
specificallydesignedtohandleonetypeofgeophysicaldata,suchasseismic,electromagnetic,
gravity,welllogs,ortext,andtooptimizetheirperformancefortasksthatareuniquetothat
particulardatatype.Theprimaryroleofmodality-specificmodelsistolearnrichrepresentationsthat
canserveasstrongembeddingsforsubsequentmultimodalmodeltraining,andtoprovideasolid
foundationforfine-tuningondownstreamgeophysicaltasks.Modality-specificmodelsoftenemploy
advancedself-supervisedlearningtechniquessuchasgenerativepretrainedtransformers1andMAE83
tolearnthesepowerfulrepresentations,enablingthemtocapturecomplexrelationshipswithinthe
data.
Inthefieldofexplorationgeophysics,modality-specificmodelsareincreasinglybeingexplored
forvariousdataprocessingandinterpretationtasksthatrequireahighlevelofexpertisefocusedona
singlemodality.Forinstance,Shengetal.101(2023)developedSFMbasedonmigratedseismicdata,
whichservesasaneffectivepretrainedmodelforarangeofdownstreamtasks.Byusingtask-
specificadaptation,thisseismicmodality-specificmodelhasshowngreatperformanceintaskslike
interpolation,faultidentification,andinversion.Thisshowshowusefulandflexiblemodality-
specificmodelsareingeophysicalresearch.
Modality-specificmodelsplayacrucialroleinconnectingdifferentlevelsofGeoFMs.Theyact
asfoundationalbuildingblocksthatprovidespecializedembeddingsformorecomplexGeoFMs.
Multimodalmodelsoftenusetheembeddingsfromthesemodelsastheirbasis,enhancingthe
representationpowerbyprovidingwell-optimized,modality-specificfeaturesthatcaneffectively
integratewithothermodalities.Throughtechniquessuchasfine-tuning,modality-specificmodels
canbeadaptedtovariousdownstreamtasks,enhancingtheirperformanceintask-specific
applications.Thefactthatmodality-specificmodelsactasalinkbetweentask-specificmodelsand
higher-levelintegratedsystemsshowshowimportanttheyareforbuildingacohesiveand
multilayeredgeophysicalmodelingframework.
4.1.4Task-specificModels
Task-SpecificModelsareatthefoundationallevelofGeoFMs,specificallydesignedtoaddress
well-definedseismictasksusingtargetedlearningapproaches.Unlikemodality-specificmodelsthat
focusonmasteringaparticulardatatype,task-specificmodelsaimtosolveparticularproblemssuch
asdenoising,interpolation,first-arrivalpicking,faultdetection,orseismicimaging,utilizingthe
embeddingslearnedfrommodality-specificmodelstoenhancetheirperformance.Thesemodelsare
tailoredtohandlespecificchallengesinexplorationgeophysics,directlycontributingtothe
efficiencyandaccuracyofoperationalworkflows.Inexplorationgeophysics,task-specificmodels
havebeenutilizedtohandlehighlyspecializedtasksthatrequirepreciseproblem-solvingcapabilities.
Forexample,amodeldesignedforfaultdetectionmaybeusedtopinpointfaultlocationsinseismic
datasets,whileanothermodelforseismicinversionmayfocusonestimatingsubsurfaceproperties
basedonseismicreflectiondata.
Task-specificmodelsareessentialinthebroadercontextofGeoFMs,servingastheendpoints
forapplyingfoundationalknowledgetopracticalapplications.Byusingtherichrepresentations
learnedfrommodality-specificmodels,task-specificmodelscanachieveahigherlevelofaccuracy
andgeneralizationcapabilityintheirrespectivetasks.Thisapproachensuresthateachspecific
problemisaddressedwithoptimalprecision,whilealsoallowingtask-specificmodelstobe
seamlesslyintegratedintomultimodalmodelsorgeophysicalagentandcopilot,whichrequire
specializedtasksolutionsaspartoftheiroverallfunctionality.
4.1.5DataBasis
ThedatabasisservesasthefundamentalbuildingblockforallGeoFMs.Itinvolvesthe
collection,preparation,andcurationofdiversegeophysicaldatasetsusedasinputfortrainingmodels
withintheGeoFMshierarchy.Thisincludesvariousgeophysicaldatatypes,suchasseismicrecords,
electromagneticmeasurements,gravitydata,welllogs,geophysicaltextdata,andtask-specificdata
pairsfordifferentgeophysicalchallenges.Forexample,ifwewanttotrainafoundationmodelfor
prestackseismicdatadenoising,wefirstneedalargeamountofshotgatherstotrainafoundation
modelfortheprestackdatamodality.Next,wetrainamodelspecificallyforseismicdenoisingby
usingnumerousdenoisingsamplepairsfordifferenttypesofnoise.
Ensuringquality,diversity,andcomprehensivenessofthesedatasetsiscrucialfordeveloping
reliablemodelsacrossallGeoFMslevels.Thedatabasisformsthegroundworkforallmodeling
efforts,supportingthetrainingofmodality-specificmodelsaswellastask-specificmodels,enabling
end-to-endtrainingtosolvespecificgeophysicalchallenges.Formodality-specificmodels,thedata
basisprovidesthenecessarydiversityandrichnesstolearnstrong,generalizablerepresentationsfor
eachmodality.Fortask-specificmodels,thedatabasissuppliescarefullycurated,task-orienteddata
pairsthatallowmodelstobetrainedeffectivelyforpreciseapplications.Thisinterconnected
structureensuresthateachleveloftheGeoFMhierarchybenefitsfromarobustdatafoundation,
enablingseamlessprogressionfromfoundationaldataanalysistocomplexgeophysical
interpretations.
4.2DevelopmentWorkflowforGeoFMs
ToeffectivelydevelopGeoFMs,astructuredandsystematicapproachisessential.Thissection
introducesageneralizedworkflowdesignedtoguidethedevelopmentofGeoFMs,whichcoverskey
stagesincludingdatapreparation,pretraining,multimodalalignment,andadaptationfortask-specific
applications,asshowninFigure4.Weoutlinethesestagestoprovideacomprehensiveworkflow
thatcanadapttovariousgeophysicaltasks,ensuringaconsistentmethodologyforbuildingpowerful
andversatileGeoFMscapableofaddressingthecomplexchallengesinherentinexploration
geophysics.
Figure4ThedevelopmentworkflowofGeoFMs,includingdatapreparation,pretraining,multimodalalignment,
andtask-specificadaptation.Theillustrationofself-supervisedlearningisrepaintedfromthesurveyproposed
byLiuetal.169
4.2.1DataPreparation
DataservesasthecornerstonefordevelopingrobustGeoFMs,wherethehierarchyofGeoFMs
intodifferentlevelsemphasizestheimportanceofcomprehensivedatasets.Datapreparationis
crucialnotonlyfortrainingtask-specificmodelsbutalsoforenablingthedevelopmentofhigher-
levelmodels,suchasmodality-specificandmultimodalGeoFMs.Thequalityanddiversityofdata
directlyimpactthemodel'sabilitytogeneralizeacrossdifferentgeophysicalapplications,making
datapreparationafoundationalaspectoftheentireworkflow.InthecontextofGeoFMdevelopment,
datapreparationinvolvesseveralkeysteps,includingdatacollection,preprocessing,andlabeling,as
showninFigure5.
Figure5KeystepsfordatapreparationinthedevelopmentworkflowofGeoFMs.
TheprimarysourcesofdataforGeoFMsincludeforwardmodelingsimulation,open-source
data,proprietarydatafromoilandgasexplorationcompanies,anddatageneratedthroughgenerative
models.Forwardmodelingsimulations,utilizingtechniqueslikefinite-differencemodelingand
finite-elementalgorithms138basedonthewaveequation,providesyntheticdatasetswheresubsurface
propertiesandgeologicalscenariosarepreciselydefined.Whilethesesyntheticdatasetsare
invaluableforunderstandingtheoreticalresponsesandtestingalgorithms,theyoftenlackthe
complexity,noisecharacteristics,andvariabilityofreal-worlddata,limitingtheirutilityforaccurate
modelperformanceinpracticalscenarios.Open-sourcedataoffersaccesstorealgeophysicaldata,
enablinginitialmodeltrainingandvalidation.However,thesedatasetsaretypicallylimitedin
volumeandmayvaryinquality,makingtheminsufficientfortraininghigh-performanceGeoFMs.
Themostcriticaldatacomesfromproprietarysourcesheldbyoilandgasexplorationcompanies.
Theselarge-scale,high-qualitydatasets,whichencompassawiderangeofgeologicalsettingsand
subsurfacecomplexities,arecrucialfordevelopingGeoFMscapableofgeneralizingeffectivelyto
real-worldexplorationtasks.Accessingthisdataoftenrequirescollaborationbetweenindustryand
researchinstitutions,highlightingtheimportanceofmulti-institutionalpartnerships.Toaddressdata
scarcity,generativemodelssuchasGAN,VAE,anddiffusionmodels135offerpromisingsolutionsby
learningthestatisticaldistributionsofrealdataandgeneratingnew,realisticsamples.Thesemodels
canaugmentexistingdatasets,simulaterareevents,andaddressunderrepresentedscenarios,
improvingtherobustnessandgeneralizationofGeoFMs.Combiningthesediversesourcesofdatais
keytobuildingpowerfulmodelsthatcantacklethecomplexitiesofgeophysicalexploration.
DatapreprocessingisacriticalstepinpreparinggeophysicaldatasetsfortrainingGeoFMs.It
consistsoftwomainstages:datacleaninganddataintegration.Datacleaninginvolvesremoving
errorsandinconsistenciesthatcanadverselyaffectmodelperformance.Thisincludeseliminating
"badtraces"inseismicrecords,whichmayarisefromfaultysensorsorpoorsignalquality,aswellas
filteringoutstrongnoiseinterferencefromexternalsources.Additionally,redundantorduplicate
datapointsareremovedtoensurethatthemodeltrainsonuniqueandrelevantsamples,further
enhancingthequalityofthedata.Dataintegrationfocusesontransformingandstructuringthedata
tofittheinput-outputformatrequiredbythemodel.Thisincludesformattingthedatatomatchthe
network’sarchitecture,suchasadjustingseismicdatatofixed-lengthtimewindowsorintegrating
geophysicalmeasurementsintocompatibleformats.Fordifferenttasks,end-to-enddatasetsare
curatedbycombiningvariousdatasources,suchasseismic,welllogs,andgravitydata,tocreate
comprehensivetrainingsets.Commonoperationslikenormalizationandstandardizationarealso
appliedtoensureconsistentdatascalingandpreventfeatureswithlargemagnitudesfromskewing
themodel’slearningprocess.
Datalabelingisessentialforpreparinghigh-qualitylabeleddatasetsthatsupportthetrainingof
GeoFMs.Itinvolvestwomainstrategies:manuallabelinganddeeplearning-assistedlabeling.
Manuallabelingreliesonspecialistsorprofessionalsoftwaretoannotategeophysicaldata,including
taskslikedataprocessing,seismicimaging,andgeneratingdetailedanalysisreports.Thesedatasets
arecrucialforensuringaccurateannotationsthatreflectcomplexgeologicalconditions.Ontheother
hand,deeplearning-assistedlabelingleveragesadvanceddeeplearningmodelstofacilitateand
enhancethelabelingprocess.Forinstance,SAMmodelscanassistinautomaticallylabelingfirst-
arrivalpicking,ataskthatwillbefurtherdiscussedinsubsequentsections.Theintegrationofdeep
learningtechniquesintothelabelingprocessoffersdistinctadvantages,particularlyintermsof
scalabilityandconsistency.Thesemethodsnotonlyexpeditetheannotationoflargedatasetsbutalso
ensurealevelofuniformityinlabelingthatisoftenchallengingtoachievethroughmanual
annotationalone.Moreover,deeplearning-basedapproacheshavethecapacitytotacklecomplex,
high-dimensionaltasksthatwouldbeotherwisecumbersomeandpronetohumanerror.Assuch,the
roleofdeeplearningindatalabelingisbecomingincreasinglypivotalinthecontextofGeoFM
development,enablingthecreationofcomprehensive,high-qualitylabeleddatasetsthatareessential
fortheeffectivetrainingofrobustmodels.
4.2.2Pretraining
PretrainingisacrucialphaseinthedevelopmentofGeoFMs,asitallowsmodelstolearn
generalizedrepresentationsfromlarge-scalegeophysicaldatasetsbeforebeingfine-tunedforspecific
tasks.Duringthisstage,GeoFMsareexposedtovastamountsofdatatocaptureunderlying
structuresandfeatures,whichcanthenbetransferredtodownstreamapplications.Pretraining
providesthefoundationalknowledgenecessaryforGeoFMstoexcelacrossvariousgeophysical
tasks,significantlyreducingthedataandcomputationalrequirementsforsubsequenttask-specific
adaptations.Wemainlyfocusonself-supervisedpretraining,whichhasbecomeakeyparadigmin
foundationmodeldevelopment.Inthisapproach,themodelcanleverageunlabeleddatabycreating
auxiliarytaskstolearnusefulrepresentationsandisallowedtoextractfeatureswithoutrequiring
explicithuman-providedlabels.Here,weexploretwoprimaryself-supervisedpretrainingparadigms:
generativepretrainingandcontrastivepretraining,asshowninFigure6.
Figure6Anoverviewofself-supervisedpretrainingmethods.
Generativepre-trainingisageneralmethodusedtotrainmodelsonlargeamountsofunlabeled
databeforefine-tuningthemforspecificdownstreamtasks.Thegoalisforthemodeltolearn
generalpatterns,distributions,andrepresentationsindatathatcanbeappliedacrossvarious
applications.Generativepretrainingtypicallyinvolvesgenerativemodels,reconstructivetasks,and
autoregressivetasks.
Oneofthekeystrategiesingenerativepretrainingisusinggenerativemodels,suchas
generativeadversarialnetworks133(GANs)anddiffusionmodels134,135,tolearnrepresentationsfrom
large,unlabeledgeophysicaldatasets.Thesemodelsaretrainedtocapturedatadistribution,whichis
crucialforpretrainingGeoFMs.GANs,composedofageneratorandadiscriminator,arecommonly
usedinpretrainingtaskswherethegoalisforthegeneratortolearntoproducesyntheticdatathat
closelymirrorsrealdatadistributions.Inthecontextofgeophysicaldata,GANscanbeemployedto
learnrepresentationsofseismicwaveformsorgeologicalfeaturesbytrainingthegeneratorto
producedatathatisindistinguishablefromactualseismicdata.AlthoughGANsarewidelyusedfor
datageneration,theirprimaryroleinpretrainingGeoFMsistohelpthemodellearnbroad,
generalizedpatternsandrepresentationsofgeophysicalprocessesthatcanbetransferredtospecific
downstreamtasks.Diffusionmodels,suchasStableDiffusion136,areanotherpowerfultoolfor
pretraining,offeringanalternativetoGANswithmorestablelearningdynamics.Diffusionmodels
learntoreversetheprocessofnoiseaddition,graduallydenoisingdatatoreconstructit.This
denoisingprocessenablesthemodeltolearncomplexdatadistributionswithoutrequiringexplicit
labels,makingitastrongcandidateforpretrainingonunlabeledgeophysicaldatasets.Stable
Diffusion,inparticular,hasdemonstratedtheabilitytogeneratehigh-quality,detailedsamplesfrom
noisydata,whichcanbeinvaluableinlearningrepresentationsofseismicdata,geologicalstructures,
andothergeophysicalphenomena.Themodel’sabilitytoreconstructdatabyprogressivelyrefining
italignswellwiththeprocessofextractingusefulfeaturesandpatternsfromcomplexgeophysical
datasets.
Anothergoodwaytouseself-supervisedpretrainingiswithreconstructivetasks.Inthesetasks,
themodellearnstoguesswhatpartsoftheinputdataaremissingorbroken,whichhelpsitbuilda
compactandusefulrepresentationofthedata.Thisapproachisparticularlyusefulforlearning
generalizablefeaturesfromunlabeledgeophysicaldatasets.Thetwomainstrategiesinthisparadigm
aremaskpredictionandautoencoder.Maskprediction,asexemplifiedbyMAE116,isinspiredby
BERT137whichconvertsimagesintosequencessimilartotextandpredictsthemaskedportions.In
thecontextofseismicdata,MAEcanbeusedtomaskportionsofseismicinputandtrainthemodel
toreconstructthemissingsections,encouragingthemodeltocaptureessentialgeologicalfeatures.In
thegeophysicalfield,theseismicfoundationmodel(SFM)proposedbyShengetal.110employsthis
approach,usingmaskedmigratedseismicdatatolearnvaluablerepresentations.Additionally,
autoencoder,whichlearntoencodedataintoalower-dimensionallatentspaceandthendecodeit
backtotheoriginalinput,arealsoeffectiveforlearningdatarepresentationswithoutlabeledsamples.
Theseapproachesalignwellwithdataprocessingtasksinseismicanalysis,suchasnoiseattenuation
anddataenhancement.Besides,thisapproachisparticularlybeneficialinseismicinterpretationtasks,
wherehigh-dimensionaldataisoftenincompleteorcorrupted.
Autoregressivetasksrepresentapowerfulpretrainingstrategywherethemodelgeneratesdata
sequentially,predictingeachtokenbasedonpreviouslygeneratedtokens.TheGPT1modelsare
basedonautoregressivegenerationandhaveachievedremarkablesuccess,especiallyforNLPtasks.
Duringautoregressivepretraining,themodellearnstocapturethetemporalandcontextual
dependencieswithindatasequences,enablingittogeneratecoherentandcontextuallyrelevant
outputs.BeyondNLP,theautoregressiveparadigmhasbeenextendedtootherdomains,including
computervisionandmultimodaltasks,withnotableimplementationssuchasAnyGPT130.Inthe
contextofgeophysicalapplications,autoregressivemodelsoffersignificantpromiseformodeling
sequentialortime-seriesdata,suchasseismicdata,welllogs,ormultimodalgeophysical
measurements.Thesemodelscanlearnthedependenciesbetweenpastandfuturedatapoints,
facilitatingthegenerationofcontextuallyrelevantgeophysicalinterpretations.Whileseismicdata
necessitatesspecializedpretrainingtoaccountforitsuniquecharacteristics,textualdata—suchas
explorationreports,drillinglogs,orgeophysicalanalysisreports—canbenefitfromtherich
pretrainedknowledgeembeddedinLLMs.LLMs,whicharepretrainedonvastcorporaoftextual
data,excelinunderstandingbothstructuredandunstructuredtext.Byfine-tuningthesemodelson
domain-specificgeophysicaldatasets,suchasexplorationreportsordrillinglogs,theycanbe
adaptedtogeneratehighlyrelevantandcontextuallyaccurateoutputsinthedomainofexploration
geophysics,therebysupportingtaskssuchasreportgeneration,interpretationofgeophysicalfindings,
anddecision-making.
Contrastivepretrainingfocusesonlearningrepresentationsbydistinguishingbetweenpositive
andnegativedatasamples.Themodelistrainedtomaximizethedistancebetweendissimilar
samplesandminimizethedistancebetweensimilarsampleswithinasharedrepresentationspace.
Twoprominentparadigmsofcontrastivelearningarecontext-instancecontrastandinstance-instance
contrast,eachfocusingondifferentlevelsofrepresentationandlearningobjectives.Ascontrastive
learningtechniqueismainlyusedinmultimodalalignmenttasks,thissubsectionprovidesabrief
overview,withfurtherdiscussionsonitsapplicationinmultimodalgeophysicaldataintegrationin
thefollowingsubsection.
Context-instancecontrastfocusesonlearningtherelationshipbetweenalocalfeatureandits
broadercontext.Byconnectingaspecificfeaturetoitsglobalcontext,themodelbetterunderstands
thedependenciesbetweenlocalandglobalcomponents.InGeoFMsapplications,thismethodis
usefulwhenstudyingseismicdataorgeologicalfeaturesinrelationtolargerregionalstructures.For
instance,wheninterpretingalocalseismictrace,themodellearnstorelateittobroadergeological
formationsorregionaltrends.Instance-instancecontrastemphasizeslocalfeature-to-feature
relationships,wherethemodelfocusesondistinguishingindividualinstancesbasedontheirinherent
characteristics.InGeoFMs,thismethodhelpsthemodeltorecognizeandclassifylocalfeatures,
whicharecrucialfortaskslikefaultdetection,horizonidentification,orreservoircharacterization.
Contrastivepretraininghelpsthemodeldistinguishbetweensimilaranddissimilarseismictraces,
improvingitsunderstandingofgeologicalpatterns.Specifically,contrastivepretraininginvolves
constructingpositiveandnegativepairsofseismictraces,wherepositivepairsaresimilar(e.g.,
tracesfromthesamegeologicallayer),andnegativepairsaredissimilar(e.g.,tracesfromdifferent
regionsorwithdistinctfeatures).TechniqueslikeSimCLR131orMoCo132canbeadapted,where
augmentationsareappliedtocreatedifferentviewsofthesameseismictrace.Theseviewsarethen
contrastedwithtracesfromdifferentareastohelpthemodellearndistinguishingfeatures.
4.2.3MultimodalAlignment
Multimodalalignmentisacriticaltechniquethatenablestheintegrationofdifferenttypesof
data(ormodalities)intoaunifiedrepresentationspace.Transformer-basedmodels,whichhave
gainedwidespreadattentioninvariousmultimodaltaskssuchasimage-textpairing44,text-to-speech
alignment146,andvideoanalysis147,offerarobustframeworkforachievingcross-modalalignment.
Geophysicalmodels,whichrequiresimultaneousprocessingofvariousdatatypesformoreaccurate
analysisandinterpretation,greatlybenefitfromthisalignment.InthecontextofGeoFMs,thiscan
involvealigninggeophysicaldata,likeseismictraces,welllogs,andgeologicalimages,withother
modalities,suchasnaturallanguagedescriptions,technicalreports,orotherdatatypesrelatedto
geologicalanalysis.Toachievethis,twomaincomponentsareinvolved:themodalityencoderand
themodalityinteraction,asshowninFigure7.
Figure7Anoverviewofthemultimodalgenerationprocess.
Inmultimodalalignment,themodalityencoderplaysacrucialroleintransformingrawinput
dataintocompact,semanticallydensefeaturerepresentations.Theserepresentationscapturethe
essentialcharacteristicsofthedata,enablingthemodeltoprocessandanalyzecomplex,
heterogeneousinformationmoreeffectively.Acommonstrategyistoleveragepre-trainedencoders
thathavebeentrainedonlarge-scaledatasetstoalignfeaturesfromdifferentmodalities,suchas
imagesandtext.Forinstance,inmodelslikeCLIP44,avisualencoderistrainedtoassociateimage
featureswithtextualdescriptions.Thisallowstheencodertobefine-tunedoradaptedtonewtasks,
makingiteasiertointegrateandprocessmultimodaldata,suchascombiningseismicdatawith
geologicalreportsorimagesinthecaseofGeoFMs.
Oncethedatafromdifferentmodalitieshasbeenencodedintofeaturespaces,themodality
interactionplaysacrucialroleinaligningandfusingtheserepresentationssothataunifiedmodel
canunderstandandreasonoverthemeffectively.Therearetwoprimarywaysofintegrating
multimodalinformationintoasharedframework:token-levelfusion148andfeature-levelfusion149,150.
Token-levelfusiontransformsfeaturesfromdifferentmodalitiesintotokenrepresentations,
whichcanthenbecombinedandprocessedbythemodel.Thismethodisparticularlyeffectivefor
multimodaltaskswhereeachmodalitycanberepresentedasasequenceoftokens.Thetransformed
tokensfromeachmodalityarethenconcatenatedandsentintothemodel.Forinstance,BLIP-257
proposedaQueryingTransformer(Q-Former)thatuseslearnablequeriestoextractrelevantfeatures
fromthecharacteristicsofdifferentmodalities,andtheseselectedfeaturesarethenfedasprompts
intotheLLM.Advancedmethods,X-Former151,enhancevisualrepresentationsthroughan
innovativeinteractionmechanism,whichcombineshigh-frequency,detailedfeaturesfrommasked
imagemodelingwithlow-frequency,semanticallyrichfeaturesfromcontrastivelearning.Incontrast,
somemethods152,153usetheMLPasalearnableconnectortolinkfeaturesfromdifferentmodalities.
Feature-levelfusion,ontheotherhand,involvesdeepintegrationbetweenthefeaturesof
differentmodalities,whereeachmodality'sfeaturesinteractatadeeperlevel.Thisapproachallows
formorecomplexinteractionsbetweenmodalities,enablingthemodeltolearnricherrepresentations
fromcross-modalrelationships.ThesurveyproposedbyXuetal.168summarizessixtypesof
transformer-basedcross-modalinteractions.Thecommonmethodsinclude:(1)EarlySummation139,
wheretokenembeddingsfromdifferentmodalitiesareweightedandsummedbeforebeingprocessed;
(2)EarlyConcatenation140,whichmergesmodalityembeddingsintoasinglesequenceforunified
processing;(3)HierarchicalAttention(Multi-streamtoOne-stream)141,whereseparatestreamsfor
eachmodalityarefusedatalaterstage;(4)HierarchicalAttention(One-streamtoMulti-stream)142,
whereasharedTransformerinitiallyprocessesthedata,followedbyindependentstreams;(5)Cross-
Attention143,whereeachmodalityattendstotheotherbyusingqueryembeddingsfromonemodality
toattendtokeyandvalueembeddingsfromtheother;and(6)Cross-AttentiontoConcatenation144,
wherethecross-attendedfeaturesfromeachmodalityareconcatenatedandprocessedtogetherbefore
passingthroughanotherlayer.ForGeoFMs,feature-levelfusioncouldbeappliedtocombine
featuresfromseismicdata,geologicalimages,andwelllogsatdeeperlevels.Forinstance,adeep
cross-attentionmechanismmightbeusedtofuseseismicfeatureswithgeologicalimagefeaturesor
textualdescriptionsofgeologicalstrata.Dualinteractionlayerscanbeintroducedbetweenseismic
dataandgeologicalfeatures,allowingthemodeltorefineitsunderstandingofhowseismicsignals
correspondtospecificgeologicalstructures.
TheLanguageBind145approachproposesusinglanguageasthecentralmodalitytoalignother
datatypeseffectively.Thisstrategy,whichhasbeenappliedsuccessfullytovision,infrared,depth,
andaudiodata,canbeadaptedtoexplorationgeophysicstobringtogetherseismic,welllogs,
electromagnetic,andotherdata.Byfreezingthepretrainedencoderandusingcontrastivelearning,
modelsforeachgeophysicalmodalitycanbetrainedtoalignwiththecentralmodality,resultingina
unifiedfeaturespaceacrossallmodalities.
Besides,ageoscientificcorpuscouldbeusedasthecentrallanguagemodality,whileseismic
dataandothergeophysicalmeasurementscouldbealignedtothisspaceusingencoderstrainedvia
contrastivelearning.Thegeophysicaldatacanberepresentedthroughembeddingtechniquesthatare
similartotheapproachoftreatingdepthorinfrareddataasRGBimages.Multimodallargelanguage
modelscancombineseismicwaveforms,electromagnetic,andgravitydatawithgeologicaltextual
informationtoautomaticallyidentifysubsurfacestructures,suchasreservoirsorfaults,thereby
improvinginterpretationefficiency.
4.2.4AdaptationforTask-specificApplications
Whenadaptingpre-trainedGeoFMsforspecificgeophysicaltasks,fine-tuningiscrucialto
customizethemodeleffectivelywhileminimizingcomputationalrequirements.Giventhelargesize
ofpre-trainedmodels,Parameter-EfficientFine-Tuning(PEFT)methodsofferaneffectivesolution
byallowingadaptationwithminimalmodificationstothecoremodel.Here,wediscussfour
commonlyusedfine-tuningapproaches:additivefine-tuning,selectivefine-tuning,reparametrized
fine-tuning,andhybridfine-tuning,asshowninFigure8.
Figure8AnoverviewofParameter-EfficientFine-Tuning.
Additivefine-tuningmethodsfocusonintroducingextraparameterstothepre-trainedmodel
withoutmodifyingitscorestructure.Thesemethodsaddtask-specificcomponents,suchasadapters
oradditionalprompts,whichcanbefine-tunedwhileleavingtherestofthemodelfrozen.This
allowsfortaskadaptationwithminimalcomputationaloverhead.Onepopularmethodistheuseof
adapter154layers,whicharesmallneuralnetworkmodulesaddedbetweenthelayersofthepre-
trainedmodel.Adaptersaretrainedduringfine-tuningwhilethepre-trainedweightsremainfixed.
Thistechniqueishighlyparameter-efficient,asitintroducesonlyasmallnumberofadditional
parametersrelativetotheentiremodel.AdaptershavebeenusedsuccessfullyinNLPtaskslike
questionansweringandtextclassification,aswellasinvisiontasks.Amorerecentapproach,prompt
tuning155,involvesaddinglearnableembeddings(prompts)totheinputsequence.Theseprompts
helpthemodelattendtothemostrelevantfeaturesforthetaskathandwithoutalteringthe
underlyingweightofthemodel.Softprompts156canbeseenasaformof"task-specificattention"
thatguidesthemodel'sfocus.Further,prefix-tuning157optimizesacontinuoussetofpromptvectors
(prefix)addedtotheinputofapre-trainedmodeltoguideitsgenerationtask.Thisapproachallows
themodeltoadapttothenewtaskbytrainingonlytheprefixtokenswhilekeepingtherestofthe
modelfixed.
Selectivefine-tuninginvolvesupdatingonlyasmallsubsetofthemodel’sparameters,typically
targetingspecificlayersorcomponentsthataremostrelevantforthetask.Thisreducesthe
computationalburdenandhelpsmitigateoverfittingbyavoidingunnecessaryadjustmentstothe
entiremodel.Forinstance,biasadjustment158,159involvesupdatingonlythebiastermsincertain
layersofthemodel,leavingthemajorityofweightsuntouched.Anothercommonapproachislayer-
wisefine-tuning,whereonlycertainlayersofthemodelareupdated.Forexample,Gheinietal.160
proposetofine-tuneonlythecross-attentionlayers.Suchamethodisparticularlyusefulincases
wherethelowerlayerscapturegeneralknowledgethatdoesnotneedtobealtered.Furthermore,LT-
SFT161learnssparse,real-valued,task-specificandlanguage-specificmasksbasedontheLottery
TicketHypothesis,whicharethencomposablewithapretrainedmodeltoenableefficientfine-
tuning.
Reparameterizedfine-tuningtechniquesaimtodecomposemodelparametersintomoreefficient
representations,makingiteasiertoadaptthemodeltonewtaskswithoutsignificantlyincreasing
computationalcosts.Low-RankAdaptation(LoRA113)isapopularreparameterizationmethodwhere
weightmatricesaredecomposedintolow-rankmatrices,makingitpossibletoupdateonlythelow-
rankcomponentsduringfine-tuning.Thisdrasticallyreducesthenumberoftrainableparameters,
makingitparticularlyusefulforlargemodels.TheLoRA+162methodimprovesupontheoriginal
LoRAbysettingdifferentlearningratesforthetwolow-rankadaptermatrices,correctingthe
suboptimalfeaturelearningthatariseswhenbothmatricesareupdatedwiththesamelearningrate.
Theadvancedapproach,Laplace-LoRA163,appliesLaplaceapproximationtothelow-rankadaptation
parametersoffine-tunedlargelanguagemodels,improvingtheircalibrationbyestimating
uncertainty.TheLoRADropout164methodintroducesrandomnoiseandincreasessparsityinthe
learnablelow-rankmatricesofLoRA-basedmodelstocontroloverfittingduringfine-tuning,
improvinggeneralizationandmodelcalibration,andisfurtherenhancedbyatest-timeensemble
strategy.
Hybridfine-tuning165,166combinesdifferentstrategiestotakeadvantageoftheirindividual
strengths,leadingtohighlyefficientfine-tuningmethods.Forinstance,hybridfine-tuningadaptsthe
mostcriticalpartsofthemodelwhileintroducingminimaloverheadbycombiningadditiveand
selectivetechniques.
Thesefourtypesoffine-tuningofferavarietyoftoolsforefficientlyadaptingGeoFMsto
specifictasksinexplorationgeophysics.Thesefine-tuningmethodsmakesurethatGeoFMscan
adapttonewgeophysicalenvironments,givemoreaccurategeologicalinterpretations,andlower
computationalcosts.Theydothisbyselectivelyupdatingmodelparametersoraddingnewpartslike
adaptersandprefixtokens.Forexample,toimprovethemodel'sabilitytounderstandspecific
geophysicaltasks,suchaslithologyclassificationorseismicinterpretation,instructiontuning83is
performedusinginstruction-baseddata.Geoscientificquestions(e.g.,"Identifythemainlithologyin
thislogsection")arepairedwithcorrespondinggeophysicaldataandexpectedresponses.This
processhelpsadaptthepretrainedmodeltodomain-specifictasksandensuresitcaneffectively
followinstructionsinvariousgeoscientificcontexts.Besides,alignmenttuning167focuseson
improvingthealignmentacrossdifferentmodalitiestoensurethemodelcaninterpretcombined
inputs.Forinstance,themodelistrainedtojointlyprocesslogsandseismicdatawhileunderstanding
correspondinggeologicaldescriptions.Themodelusesprojection-basedorquery-basedinterfaces
andotherconnectorstomakesurethatmultimodalgeophysicaldataisinterpretedinawaythat
makessense.Thismakesiteasiertothinkaboutfeaturesandstructuresbelowthesurface.
4.2.5Examples
Inthissubsection,weusetherepresentativeworkinthefieldofexplorationgeophysics,the
SeismicFoundationModel(SFM)proposedbyShengetal.110(2023),asanexampletoillustrate
howthisworkflowfunctions.SFMisamodality-specificGeoFM,anditsmainworkflowincludes
datapreparation,modality-specificpretraining,andtask-specificadaptation,asillustratedinFigure4.
Inthedatapreparationphase,Shengetal.collected192open-source3Dmigratedseismicdatasets
andconvertedtheminto2Dseismicdataslicesalongthecrosslineandinlineforsubsequenttraining.
Inthepre-trainingphase,SFMusedMAE-basedself-supervisedlearningtechniquestoextractdata
features.Finally,inthedownstreamtaskadaptationphase,SFMadaptstodifferentdownstreamtasks
bytrainingadecoderwithasmallnumberofparameters.Thedevelopmentworkflowweproposed
mentionstheseprocessesandmethods,highlightingtheirapplicabilityandimportanceinthe
developmentofGeoFMs.
5ApplicationsandPerspectivesofFoundationModelsinExploration
Geophysics
Inthissection,weexplorethepotentialapplicationsandfutureprospectsofGeoFMsacross
differentstagesofexplorationgeophysics,includingseismicdataprocessing,imaging,and
interpretation.AsthedevelopmentofGeoFMsinexplorationgeophysicsisstillinitsearlystages,
thissectionaimstopresentaforward-lookingperspectiveonhowthesemodelscouldtransformthe
field.Byexaminingpossibleapplications,weillustratetheimmensepotentialofGeoFMsin
advancinggeophysicalworkflowsandimprovingtheefficiencyandaccuracyofexploration
activities.
Figure9presentsanoverviewofthepotentialapplicationsofGeoFMsinexploration
geophysics.Fordifferentseismictasks,avarietyofseismicfoundationmodelscanbeutilizedto
handledatafromdifferentmodalitiesandgeneratethedesiredoutputs.Additionally,LLMswith
explorationgeophysicsknowledgecanbeleveragedtofacilitateuserinteractionandorchestrate
differentGeoFMs,completingcomplexseismictasksthroughmultimodalalignmentanddecision-
making.Thissectionaimstohighlightnotonlythecurrentapplicationsbutalsothefuture
possibilitiesandadvancementsthatGeoFMscouldbringtothefieldofexplorationgeophysics.
Figure9OverviewoftheGeoFMsapplicationinthefieldofexplorationgeophysics.Usersissue
commandsbyinteractingwithseismicLLMstoprocessdifferentmodalitiesofinputdatathrough
multimodalalignmentusingsuitablefoundationmodel,andoutputtingtheresultsoftargettasks,
suchasfirst-arrivalpicking,faultdetection,faciesclassification,etc.
5.1SeismicDataProcessing
Seismicdataprocessingaimstotransformthecollectedrawseismicrecordsintoaformatthat
facilitatessubsequentseismicimagingandinterpretation.Currently,GeoFMsinexploration
geophysicsareprimarilyappliedtoseismicdatainterpretation,whiletheirdevelopmentindata
processingisstillatanearlystage.Therefore,thissectionwilldiscusstheprospectsofapplying
GeoFMstodataprocessing,includinginterpolationanddenoising.Additionally,asGeoFMsin
explorationgeophysicshavemostlyfocusedoninterpretationtaskssofar,weproposeafirst-arrival
pickingmethodbasedonSAMtodemonstratetheapplicationoffoundationmodelsingeophysics
andillustratetheirpotentialindataprocessingtasks.
5.1.1First-arrivalPickingBasedonSAM
Inseismicdataprocessing,first-arrivalpickingplaysapivotalroleinestimatingthesubsurface
velocitystructure,asitpinpointstheinitiationofthefirstsignalarrivals.Inrecentyears,deep
learningmethodshavebeenabletoachieveexcellentfirst-arrivalpickingresultsonsimilardatasets
aftertraining.However,thegeneralizationperformanceofdeeplearningmethodsissignificantly
affectedbythenoiseanddifferencesindatadistribution.
SAM2,developedbyMetaAI,isconsideredthefirstfoundationmodelforcomputervision.
Withitstrainingconductedonamassivecorpusofdata,whichencompassesmillionsofimagesand
billionsofmasks,SAMdemonstratesarobustcapabilityofdeliveringeffectivesegmentationresults
acrossawiderangeofimagesegmentationtasks.Thefirst-arrivalpickinginseismicdataisalsoa
segmentationtask.Thus,employingSAMforthistaskpresentspromisingprospects.Therefore,we
proposetheapplicationofSAMdirectlytothetaskoffirst-arrivalpickinginseismicdata,to
demonstratetheimpactoflargemodelsontheparadigmofexplorationgeophysicsresearch.
SAMiscomposedofthreeparts:apromptencoder,animageencoder,andamaskdecoder.The
promptencoderservestoencodetheprompt(mask,points,box,andtext)intoembedding,whilethe
imageencoderisapre-trainedmodelbasedontheViT41architecture.Themaskdecoderisa
lightweightmodulethatupdatesbothimageandpromptembeddingsthroughcross-attention,which
isultimatelyusedfordynamicmaskoutputs2.Theprocessofthefirst-arrivalpickingbasedonSAM
isshowninFigure10.TherearetwowaystouseSAM.Thefirstistodirectlyutilizetheautomatic
segmentationfeatureofSAMandthenselectthelargestmaskasthefirst-arrivalpickingresult,since
theseismicdatausuallyoccupiesthelargestpartoftheimage.Thesecondmethodinvolves
manuallysettingprompts,whichcanachievebetterresultswhenamorerefinedsegmentationis
needed,andithasafasterrunningspeed.However,thedrawbackisthatitrequiresmanualsettings
oftheprompts.
Figure10OverviewofSAM-basedfirst-arrivalpickingmethod.Theseismicdataandtheprompt
areencodedseparatelyintoembeddingsbytheimageencoderandthepromptencoder,and
subsequentlyfedintothemaskdecodertogeneratethefirst-arrivalpickingresults.
TobettershowcasethehighgeneralizationabilityofSAManditscapabilitytofullyautomate
thefirst-arrivalpickingprocess,wepresenttheresultsobtainedbythefirstmethod.Theseismicdata
usedfortestingarederivedfromthepublicHalfmileandSudburydatasets,publishedbySt-Charles
etal.78(2021).Thesedatasetsareverynoisy,makingitchallengingtoobtainaccuratefirst-arrival
pickingresults.Thefirst-arrivalpickinglabelsfor84.45%ofthetraceswereprovidedbyexpertsin
thesetwodatasets.Figure11a-cpresentthelinegathersandcorrespondinglabelsfromtheHalfmile
andSudburydatasets,whicharechallengingformanualpickingandonlyprovidealimitednumber
oflabelsacrossthethreelinegathers.TodemonstratethegeneralizationabilityoftheSAM-based
methodonseismicdataanditsrobustnesstonoise,wedirectlyapplySAMtothedatawithoutany
specialtreatment.Andtheresults,representedbygreenpoints,areshowninFigure11d-f.Evenin
areasofstrongnoiseinterferencewherenolabelsareprovided,theSAM-basedfirst-arrivalpicking
methodcanstillproduceeffectiveresults.
(a)testdata(Halfmile) (b)testdata(Sudbury) (c)testdata(Sudbury)

(d)SAM-basedresult(Halfmile)(e)SAM-basedresult(Sudbury)(f)SAM-basedresult(Sudbury)
Figure11SAM-basedfirstarrivalpickingresults.(a-c)TestdatafromtheHalfmile,Sudbury
datasets,andtheprovidedfirst-arrivalpickinglabels,whichweredeemedvalidbyexperts.(d-f)
First-arrivalpickingresultsbasedonSAM.
DespitetheexcellentperformanceoftheSAM-basedfirst-arrivalpickingmethodonseismic
data,therearestillmanyissuesworthyoffurtherstudy.First,theefficiencyofthecurrentSAM-
basedmethodisrelativelylow.TakingtheHalfmiledatasetasanexample,ittakesabout5seconds
toprocessonelinegatherwithoutparallelization,whichisfarfromindustrial-levelapplications.
Hence,acceleratingtheSAM-basedfirst-arrivalpickingmethodisanimportantresearchdirectionin
thenearfuture.Secondly,theexistingSAMhasbeentrainedonimageandtextdataandhasnotbeen
adaptedtoseismicdata.Consequently,itisunabletoexecutesemanticsegmentationtaskson
seismicdata,suchasfaultdetection,identifyingareascontainingspecificnoisebasedonprovided
prompts,andsoon.PotentialfuturedirectionsinvolveutilizingtechnologiessuchasAdapter79and
LoRA80tofine-tuneSAMonseismicdata.Thesemethodshavealreadymadebreakthroughsinfields
suchasmedicine81andremotesensing82.Thefirst-arrivalpickingmethodbasedonSAM
demonstratesconsiderablepotentialandsuperiorperformance,whichcouldpotentiallyinfluencethe
researchparadigminthisfield.
5.1.2InterpolationandDenoising
Duetothelimitationsofthedatacollectionconditions,rawseismicrecordsalwayshave
problemssuchasmissingdataorcontainingvarioustypesofnoise.Thepurposeofseismicdata
interpolationistorecoverdatafromsparsesamples,whiletheaimofdenoisingistoseparatevalid
signalsfromnoise.Inthepracticeofseismicdataprocessing,seismicdataaretypicallytransformed
intotwo-dimensionallinegathers,similartotheformatofimages.Theresemblancehasledtothe
adoptionofimageprocessingtechniquesinmostofthecontemporarydeeplearning-basedseismic
dataprocessingmethods.Consequently,wecanalsoadopttheimageprocessingfoundationmodels
todevelopseismicdataprocessingfoundationmodels.
Intherawseismicdata,themissingdataandnoiseareverycomplex,andthedistributionof
datavarieswildlyamongdifferentseismicdata,impedingthegeneralizationabilitiesofmodelsand
thusaffectingthewideapplicationofdeeplearningmethods.Toensurethatthetrainedmodel
demonstratesrobustgeneralizationacrossvariousseismicdatasetsandprocessingtasks,thereare
twoprevailingstrategiesfordevelopingfoundationmodels.Thefirststrategyisbasedonpre-
trainingandfine-tuning.Thisstrategyinitiallyutilizesalarge-scaledatasettopretrainamodelwitha
largenumberofparametersbasedontheMAE83framework,andthenisfine-tunedindownstream
taskstoachievesuperiorperformance.Recently,Shengetal.77(2023)developedthefirstseismic
foundationmodelbasedonthepre-trainingandfine-tuningstrategy.Thismodelhasdemonstrated
remarkableperformanceinseismicdownstreamtasks.
Thesecondstrategyisbasedontheseismicdatapriorsofgenerativemodels,suchasdiffusion
model84,85,andGAN86.Thisstrategyconsistsoftwostages.Thefirststageisusuallyacorruption
encoder,whichencodesdifferenttypesofmissingdataandnoiseintolatentspace.Subsequently,the
secondstageusestheembeddingobtainedfromthefirststageaspromptsandemploysapre-trained
diffusionmodelasthedatapriorfordatarestoration.Linetal.87(2023)proposeddiffusionmodels
fortheblindimagerestorationproblem(DiffBIR),whichpre-trainedarestorationmoduleto
improvegeneralizationcapabilityandleveragedfixedstablediffusionthroughLAControNetfor
reconstruction.Wangetal.88(2023)presentedStableSR,whichonlyrequiresthefine-tuningofa
lightweight,time-awareencodertocapturethedegradationfeatures.
Intherealmofseismicdata,thedevelopmentoffoundationmodelsforinterpolationand
denoisingpresentssubstantialchallenges.First,thereisanotablelackofpre-trainedmodelsbasedon
generativemodelsservingasdatapriorsingeophysics.Secondly,incontrasttoimageprocessing
scenarios,seismicdataembodiesawidervarietyandcomplexityofnoisetypes.Consequently,the
taskoftraininganencodertograspthefeaturesofnoisebecomesasignificantproblem.Moreover,
themostcriticalissueisthelackoflargequantitiesofhigh-qualityseismicdataprocessingsamples
fortraining.Theseissuescouldbepotentialdirectionsforfutureresearchintheadvancementof
GeoFMs.
5.2SeismicImaging
Seismicimagingisatechniquethatcreatesimagesofsubsurfacestructuresbyanalyzing
seismicwaves.Itisachallengingproblembecausetraditionalmethodssuchasthefullwaveform
inversion(FWI)orseismictomographyarehighlydependentontheconstraintsofphysicsequations.
Currently,deeplearning-basedseismicimagingmethodscanbeprimarilyclassifiedintotwo
categories.Thefirstisend-to-endlearning,whichdirectlylearnsthemappingfromseismicdatato
theimagingdomain22,89.Thislearningstrategycanyieldpromisingresultsonsyntheticdatasetsthat
aresimilartothetrainingdata.However,oncetherearechangesindatadistributionormodel
parameters,theapplicationofthetrainedmodelbecomeslimitedbyitsgeneralizationcapability.The
secondcategoryemploysdeeplearningasanauxiliarytooltoassistincompletingcertainstepsin
traditionalseismicimagingmethods.Sunetal.90(2023)utilizedlearnedregularizationasaconstraint
tooptimizetheFWIprocess.Ovcharenkoetal.91(2019)extrapolatedlow-frequencyfromthe
respectivehigh-frequencycomponentsoftheseismicdatatoprovidelow-frequencyinformationfor
FWIbasedondeeplearning.
Atpresent,thesuccessoffoundationmodelsismainlyonapplicationsthatrelyonexperience
andgenerativetasks.However,thecomprehensionandlearningofphysicallawsforthesolutionsof
partialdifferentialequations(PDEs)arestillinaninitialstage.Seismicimaging,suchasFWI,relies
heavilyontheforwardmodelingofwaveequations,whichisalsothemosttime-consumingpartof
FWI.Therefore,itisextremelychallengingtoachieveadirectmappingfromseismicdatatoimages
basedonGeoFMsintheshortterm.Here,weproposetwopotentialdirectionsofdevelopmentfor
foundationmodelsinthefieldofseismicimaging.First,theaccelerationofFWIisintrinsically
linkedtotheefficientforwardmodelingofwaveequations.Therefore,theinitialresearchdirectionis
todevelopfoundationmodelsforsolvingPDEs.Inrecentyears,theemergenceofFourierNeural
Operator(FNO)89technologyhasprovidedanewperspectiveforseismicimaging90,91,especiallyin
handlingthephysics-informedconstraintsinherentinseismicdata.FNOslearntheforwardmodeling
process,mappingfromthevelocitymodeltoseismicdata,andcanaccelerateseismicimagingby
speedinguptheforwardmodelingstage.WhileFNOsofferapromisingapproachbydirectly
learningmappingsintheFourierspace,whichcanhelpimprovethegeneralizationcapabilityof
seismicimagingmodelstosomeextent,theirlimitedgeneralizationcapabilityoncomplexreal-
worlddatarestrictstheirpracticalapplication.ThislimitationarisesbecausemostFNOsaretrained
onsyntheticdatasetsandrandomvelocitymodels,whichdonotprovidethedatavolumeand
parameterscalerequiredforafoundationmodel.Yeetal.92(2024)introducedPDEformer,a
foundationmodelforsolvingPDEsbasedongraphtransformerarchitecture.However,thereremains
agapbeforeitsapplicationinseismicimaging.Thesecondpossibleresearchdirectionistointegrate
foundationmodelswithtraditionalmethodstoovercometheinherentbottlenecksinconventional
methods,suchasthelackoflow-frequencyinformation.Mostofthesedatapreprocessingmodules
canbeintegratedwithinthefoundationmodelsfortheinterpolationanddenoisingsectiondiscussed
inSection4.1.2.InspiredbytheGeoFMofweatherforecasting74,predictingthegradientchanges
duringtheFWIprocesscouldbeastrategytoaccelerateFWI.ChangingthegradientduringtheFWI
process,similartoweatherforecastingtasks,involvespredictingatrendoveracertainnumberof
timestepsatspecificgridpoints,andcanbecorrectedbasedontheresultatthecurrentmoment.
5.3Interpretation
Seismicinterpretationinvolvestheidentificationofgeologicalfeatures,includingsubsurface
structuresandproperties,tolocatepotentialtargetareasunderground.Theprocessincludestasks
suchasfaultdetection,geobodyidentificationandsegmentation,faciesclassification,andattribute
analysis.Seismicinterpretationisinherentlycomplexduetotheextensivedatavolume,theintricate
natureofsubsurfacefeatures,theuncertaintiesassociatedwithexpertinterpretations,andtheneedto
understandmultimodalinformation.Thismultimodalnaturealignswiththeearlierdiscussionon
multimodallevels,emphasizingthenecessityofcombiningdifferentdatasourcestoeffectively
interpretgeologicalfeatures.
Inthefieldofexplorationgeophysics,seismicinterpretationisoneofthefastest-growingareas
fortheapplicationofGeoFMs.Thisrapiddevelopmentcanbelargelyattributedtothesimilarity
betweenmanyseismicinterpretationtasksandthosefoundincomputervision.Forinstance,fault
detectioninseismicinterpretationcloselyparallelsedgedetectionincomputervision,whilegeobody
segmentationissimilartoobjectsegmentation.Thesesimilaritieshaveenabledfoundationalmodels
fromcomputervisiontobefine-tunedandadaptedforseismicdatainterpretation,significantly
acceleratingprogressinthisarea.Forinstance,Gaoetal.(2023)introducedafoundationmodel
empoweredbyamulti-modalpromptengine,integratingpre-trainedvisionfoundationmodelsfine-
tunedonseismicdata,whichdemonstratedpromisingresultsforuniversalseismicgeobody
interpretationacrosssurveys.Guoetal.(2023)introducedacross-domainfoundationmodel
adaptationapproachbyadaptingcomputervisionfoundationmodelstogeoscience.Theydeveloped
aworkflowthatleveragesexistingLVMsandfine-tunesthemforgeoscientifictasks,demonstrating
effectivenessinprocessingandinterpretingdatasuchaslunarimages,seismicdata,andDASarrays.
Anotherpromisingstrategyistotrainmultimodalgeophysicalfoundationmodelsfromscratch.For
example,Hanetal.(2024)introducedmulti-attributesmaskingcontrastivelearning(MAMCL)
techniqueforexplainableseismicfaciesanalysis.Traditionalmethodsoftenrequiremanualattribute
selectionandlackinterpretability,whileMAMCLusesaninterpretableframeworkwithadepthwise
CNNforfeatureextractionandaniTransformerforfeatureaggregation.Byemployingan
unsupervisedcontrastivelearningstrategy,MAMCLimprovesbothefficiencyandexplainabilityin
seismicfaciesinterpretation.
6ChallengesandFutureTrendsofGeophysicsintheEraofFoundation
Models
6.1Challenges
DespitethepromisingprospectsofGeoFMs,therearestillchallengestotheirdevelopmentand
applicationinthefieldofgeophysics.
1)DataScarcityandQuality:Thelimitationsofavailablegeophysicaldataposeaprimary
challengeinthedevelopmentofGeoFMs.Althoughthevolumeofopen-sourcegeophysicaldatais
massive,reachingTBscale,thereareseverallimitationsthathinderthedevelopmentofGeoFMs:(1)
InsufficientDataDiversity:Whileasingleexplorationareamayhavealargevolumeofseismicdata,
thereisasignificantdifferenceindatadistributionamongdifferentexplorationregions.Toenable
GeoFMstohavebettergeneralizationability,diversedatafromdifferentexplorationregionsare
required,ratherthanlargeamountsofdatafromafewtargetareas.(2)LackofLabels:Forfield
seismicdata,thereisoftenashortageofcorrespondinghigh-qualitylabeleddata,whichpresentsa
significantbottleneckintrainingmodelsthatrequirewell-curateddatasetsforsupervisedlearning.(3)
AccessRestrictions:Despitethelargevolumeofgeophysicaldata,thereisnotenoughhigh-quality
open-sourcedataavailableforGeoFMsdevelopment.Muchofthehigh-qualitydataremains
inaccessibleduetoconfidentiality,legal,andprivacyissues,limitingitsusefortrainingand
publication.Thisscarcityofhigh-qualityopen-sourcedatasignificantlyhamperstheabilitytotrain
robustmodels.Thesechallengescollectivelyimpacttheabilitytotrainmodelsthatgeneralize
effectivelyacrossdifferentgeophysicalenvironments.
2)Benchmark:Deeplearningmethodshaveachievedgreatsuccessanddevelopmentinthefield
ofexplorationgeophysics.However,unlikefieldssuchasNLPorCV,thereiscurrentlyalackof
unifiedbenchmarksforcomparisoninthegeophysicsdomain.InNLPandCV,widelyaccepted
benchmarkdatasetsandmetricsprovideastandardizedwaytoevaluateandcomparemodel
performance.Inexplorationgeophysics,differentresearchersoftenemploydifferentpreprocessing
procedures,dataselection,andevaluationmetrics,whichcanleadtosignificantdiscrepanciesinthe
resultsobtained,evenwhenusingthesameneuralnetworkarchitectureforthesametask.Thislack
ofstandardizationmakesitdifficulttoobjectivelyevaluateandcomparedifferentmodelsundera
unifiedframework,hinderingtheestablishmentofbestpracticesandslowingdownprogressinthe
field.Developingstandardizedbenchmarkdatasetsandevaluationcriteriawouldbeanimportant
steptowardfosteringmoreconsistentprogressandenablingfaircomparisonsacrossdifferent
approaches.
3)ComputationalResourcesandCosts:Trainingfoundationmodels,particularlythosewith
multimodalcapabilities,requiresvastcomputationalresources.Thetrainingprocessisacomplex
engineeringchallengethatdemandssignificanttimeandfinancialinvestment.Foundationmodels
oftenneedlarge-scaledata,multipletrainingiterations,andpowerfulhardwaresetups,whichcan
leadtomonthsoftrainingtimeandsubstantialcosts.Thecomputationalcostoftrainingsuchmodels
isoftenprohibitive,especiallyforsmallerresearchinstitutionsorcompanieswithoutaccesstostate-
of-the-arthardware.Despitethefactthatmanyoilandgascompaniespossesssubstantial
computationalresources,theseresourcesareoftennotintegratedinawaythatmeetsthe
requirementsfortrainingfoundationmodels.Inexplorationgeophysics,thetrainingofGeoFMsis
particularlyresource-intensiveduetotheneedforlarge-scalesimulations,multimodaldata
integration,anddomain-specificadaptations.Althoughsomecompanieshaveconsiderable
computationalcapabilities,theyareoftenfragmentedandlackthecohesionnecessarytomeetthe
demandsoflarge-scalemodeltraining.Additionally,theenergyconsumptionassociatedwith
traininglargemodelsraisesenvironmentalandsustainabilityconcerns,necessitatingmoreefficient
trainingtechniquesandhardwareoptimizations.Thesefactorscollectivelymakethetrainingof
foundationmodelsaresource-intensiveendeavorthatrequirescarefulplanningandefficientresource
management.
4)InterpretabilityandReliability:Inexplorationgeophysics,theneedforinterpretabilityis
paramount.Incorrectpredictionscanleadtomisguidedexplorationefforts,resultinginsignificant
financiallosses.Therefore,modelsusedinthisfieldmustnotonlybeaccuratebutalsointerpretable
andreliable.Foundationmodels,however,areinherentlycomplex,oftenconsistingofbillionsof
parameters,whichmakesthemdifficulttointerpretandunderstand.The"blackbox"natureoflarge
foundationmodelsposesachallengeingainingthetrustofdomainexpertswhoneedtounderstand
howthemodelarrivesatitsconclusions,especiallywhenthestakesarehigh.Thelackof
transparencyinmodeldecision-makingcanbeasignificantbarriertotheiradoptioningeophysics,
whereexpertsrequireclearinsightsintothereasoningbehindmodeloutputstomakeinformed
decisions.Developingmethodstoimprovemodelinterpretability—suchasincorporatingattention
mechanisms,visualizationtools,orexplanatorymodules—willbecrucialinmakingGeoFMsmore
acceptableandtrustworthyforreal-worldapplications.Additionally,ensuringthatmodelsare
reliableunderdifferentoperationalconditionsandgeologicalsettingsisessential,asthe
consequencesofincorrectinterpretationscanhavefar-reachingimplications,botheconomicallyand
environmentally.
5)LackofPhysicalLaws:Manytasksingeophysicsarehighlydependentonphysicalprinciples.
Forexample,geophysicalimaginglargelyreliesonconstraintsimposedbypartialdifferential
equations(PDEs)thatgovernwavepropagationandsubsurfacemechanics.Foundationmodelsmust
beabletoincorporatethesephysicalprinciplestoensurethattheirpredictionsarephysically
plausibleandconsistentwithestablishedscientifictheories.However,integratingthesephysics-
basedconstraintsintodata-drivenmodelsremainsachallengingproblem,asmostexisting
foundationmodelsaredesignedprimarilyforpatternrecognitionratherthanincorporatingdomain-
specificphysicalknowledge.Mostofthesemodelsaretrainedusingautoregressiveandothersimilar
approaches,whichlackexplicitintegrationofphysicalmechanisms.Thisgaphinderstheirabilityto
accuratelyrepresentgeophysicalprocessesthatarefundamentallygovernedbyphysicallaws.
AchievingeffectiveintegrationofphysicallawsinGeoFMsiscrucialtoenhancemodelreliability
andensurethatoutputsarenotonlyaccuratebutalsoscientificallyvalid.
6)UnclearRoleandApplications:Currently,thetraditionalworkflowsandsoftwarefor
geophysicaldataprocessingandinterpretationarewell-establishedandhavematuredoverdecades
ofdevelopment.ThismaturityraisesquestionsaboutthespecificvaluethatGeoFMscanbringtothe
field.Whilefoundationmodelshaveshownpromiseintransformingindustriessuchasnatural
languageprocessingandcomputervision,theirexactroleinexplorationgeophysicsremainsunclear.
Unlikeotherdomainswherefoundationmodelscandirectlyreplaceoraugmentexistingworkflows,
theadoptionofGeoFMsingeophysicsislessstraightforward.Thetraditionalworkflowsalready
providereliableandwell-testedmethodsfordataprocessing,imaging,andinterpretation.Therefore,
itisessentialtodefinetheuniqueproblemsthatGeoFMscansolvemoreeffectivelycomparedto
existingsolutions.Forexample,geophysicalcopilotscouldserveasvaluableassistants,helping
usersoperatecomplexsoftwareprogramsormanagedownstreamtask-specificmodelsmore
efficiently,therebyenhancingtheoverallproductivityofgeophysicalworkflows.However,without
clearlyidentifyingthesespecificapplications,theintegrationofGeoFMsintothegeophysical
workflowmayfaceskepticismandresistance.Thus,articulatingaclearandcompellingcasefor
GeoFMsinexplorationgeophysicsisasignificantchallengethatmustbeaddressedtofostertheir
widespreadadoption.
6.2FutureTrends
ToaddressthechallengeshighlightedinSection6.1,thissectionoutlinesfuturetrendsthatcan
guidethedevelopmentandadoptionofGeoFMsinexplorationgeophysics.
1)DataIntegrationandBenchmarkStandardization:Toovercomethechallengeofdata
scarcityandquality,theintegrationofdiversegeophysicaldatasetsfrommultipleexplorationregions
isessential.DevelopingunifiedbenchmarksforGeoFMswillhelpestablishstandardizeddatasets
andevaluationmetrics,similartothoseavailableinNLPandcomputervision.Thesebenchmarks
willenablefaircomparisonsacrossdifferentmodelsandapproaches,fosteringmoreconsistent
progressingeophysics.Establishingwell-curatedopendatasetsandcommonbenchmarkscan
provideasolidfoundationforGeoFMtrainingandevaluation,acceleratingdevelopmentinthis
domain.
2)CollaborationAmongInstitutions:Addressingtheresource-intensivenatureofGeoFM
trainingrequirescollaborationamongdifferentstakeholders—oilandgascompanies,AIcompanies,
andacademicinstitutions.Oilandgascompaniescanprovidethehigh-qualitygeophysicaldata
neededfortraining,whileAIcompaniesanduniversitiescanofferthecomputationalresourcesand
technicalexpertiserequiredtodeveloplarge-scalefoundationmodels.Acollaborativeapproach,
leveragingthestrengthsofdifferentinstitutions,canhelpovercomeindividuallimitationsand
facilitatethetrainingofGeoFMsatscale.
3)BuildingCertaintyandInterpretabilityinComplexSystems:Interpretabilityandreliability
arecrucialfortheadoptionofGeoFMsinexplorationgeophysics.Futureresearchshouldfocuson
improvingthetransparencyofmodeldecision-makingbyincorporatingexplainableAItechniques.
Attentionmechanisms,visualizationtools,andexplanatorymodulescanhelpmakeGeoFMsmore
interpretableforgeophysicists,allowingthemtounderstandandtrustthemodel'soutputs.Moreover,
ensuringthereliabilityofGeoFMsunderdifferentoperationalconditionsisessentialtoavoidcostly
errors,makingitapriorityforfutureresearchtodevelopmodelsthatcanprovideconsistentand
reliablepredictions.
4)ModelIntegrationwithPhysicalMechanisms:FuturetrendsinGeoFMdevelopmentinclude
integratingphysicalprinciplesintodata-drivenmodels.Byembeddingphysicalconstraints,suchas
thoseimposedbypartialdifferentialequations,intothetrainingprocess,GeoFMscanproduce
predictionsthatareconsistentwithestablishedgeophysicaltheories.Hybridapproachesthatcombine
data-drivenlearningwithphysicalmodelingareexpectedtoemergeasapowerfulmethodfor
enhancingthereliabilityandscientificvalidityofGeoFMs.Thesemethodswillenablefoundation
modelstohandlethecomplexitiesofgeophysicalprocesseswhileadheringtotheunderlyingphysics.
5)DefiningClearApplicationsforGeoFMsinExplorationGeophysics:ForGeoFMstogain
widespreadacceptance,theirroleinexplorationgeophysicsmustbeclearlydefined.While
traditionalworkflowsandsoftwarearealreadymature,GeoFMscouldprovideuniquevaluein
automatingcomplextasks,integratingmultimodaldata,andenhancingdatainterpretationthrough
betteruncertaintyquantification.Geophysicalcopilots,forinstance,couldassistinoperating
complexsoftware,managingtask-specificmodels,orintegratingvariousdatasources.Identifying
specificusecaseswhereGeoFMsoutperformexistingmethodswillhelpfosterconfidenceintheir
adoptionandcreateopportunitiesformoreefficientgeophysicalworkflows.Addressingthese
challengeswillbecrucialforrealizingthefullpotentialoffoundationmodelsintransforming
geophysicalresearchandexploration.
7Conclusions
Theemergenceoffoundationmodelshasradicallytransformedtheresearchparadigmin
explorationgeophysics,shiftingfromconventional,rule-basedmethodologiestoadata-driven,
foundationmodel-basedframeworkadeptattacklingintricate,multimodalgeophysicalchallenges.
ThisstudyoffersanextensiveoverviewofGeoFMs,includingtheirpresentadvancements,hierarchy,
developmentworkflow,applicationsinexplorationgeophysics,aswellasthechallengesandfuture
trends.Wecommencedwithareviewoffoundationmodels,emphasizingtheiremergenceand
progressinthedomain.Wesubsequentlyexaminedtheirhierarchy,highlightingthevariedcapacities
ofdistincttypesofGeoFMsandthewaysinwhichthesemodelscansynergisticallyenhanceone
another.Weintroducedageneralizeddevelopmentworkflowthatoutlineskeystagesfromdata
preparationtodownstreamadaptation.Subsequently,weexaminedprospectiveusesofGeoFMsin
explorationgeophysics,concentratingondataprocessing,imaging,andinterpretationwhilealso
discussingproblemsencounteredandfuturetrendsintheiradvancement.Theadvancementof
GeoFMswillcreateboundlessopportunitiesfortechnologicalprogressingeophysicsandwillalso
revolutionizetheresearchparadigminthisdiscipline.Theupcomingjourneymaypresentmany
challenges,butwithpersistentresearchandinnovation,westandpoisedtowitnessarevolutionin
thefieldofexplorationgeophysics.
8Reference
1.Achiam,J.,etal.Gpt-4technicalreport.Preprintathttps://doi.org/10.48550/arXiv.2303.08774
(2023).
2.Kirillov,A.,etal.2023.Segmentanything.ProceedingsoftheIEEE/CVFInternational
ConferenceonComputerVision,4015-4026(2023).
3.OpenAI.Videogenerationmodelsasworldsimulators.OpenAI:
https://openai.com/research/video-generation-models-as-world-simulators(2015).
4.CastroNascimento,C.M.,&Pimentel,A.S.Dolargelanguagemodelsunderstandchemistry?a
conversationwithChatGPT.JournalofChemicalInformationandModeling.63(6),1649-1655
(2023).
5.Guo,T.,etal.Whatcanlargelanguagemodelsdoinchemistry?Acomprehensivebenchmarkon
eighttasks.AdvancesinNeuralInformationProcessingSystems,36(2023).
6.Li,Y.,Xu,H.,Zhao,H.,Guo,H.,&Liu,S.Chatpathway:Conversationallargelanguagemodels
forbiologypathwaydetection.NeurIPS2023AIforScienceWorkshop(2023).
7.Li,Y.,Wang,S.,Ding,H.,&Chen,H.Largelanguagemodelsinfinance:Asurvey.Proceedings
oftheFourthACMInternationalConferenceonAIinFinance(2023).
8.Wu,S.,etal.BloombergGPT:Alargelanguagemodelforfinance.Preprintat
https://doi.org/10.48550/arXiv.2303.17564(2023).
9.Moor,M.,etal.Foundationmodelsforgeneralistmedicalartificialintelligence.Nature,616
(7956),259-265(2023).
10.Guo,X.,etal.Skysense:Amulti-modalremotesensingfoundationmodeltowardsuniversal
interpretationforearthobservationimagery.Preprintathttps://doi.org/10.48550/arXiv.2312.10115
(2023).
11.Liu,F.,etal.RemoteCLIP:AVisionLanguageFoundationModelforRemoteSensing.IEEE
TransactionsonGeoscienceandRemoteSensing(EarlyAccess)(2024).
12.Mall,U.,etal.,Remotesensingvision-languagefoundationmodelswithoutannotationsvia
groundremotealignment.InternationalConferenceonLearningRepresentations(2024).
13.Yu,S.,&Ma,J.Deeplearningforgeophysics:Currentandfuturetrends.Reviewsof
Geophysics,59(3),e2021RG000742(2021).
14.Spitz,S.SeismictraceinterpolationintheF-Xdomain.Geophysics,56(6),785-794(1991).
15.Donoho,D.L.,&Johnstone,I.M.Adaptingtounknownsmoothnessviawavelet
shrinkage.JournaloftheAmericanStatisticalAssociation,90(432),1200-1224(1995).
16.Oropeza,V.,&Sacchi,M.Simultaneousseismicdatadenoisingandreconstructionvia
multichannelsingularspectrumanalysis.Geophysics,76(3),V25-V32(2011).
17.Sacchi,M.D.,Ulrych,T.J.,&Walker,C.J.Interpolationandextrapolationusingahigh-
resolutiondiscreteFouriertransform.IEEETransactionsonSignalProcessing,46(1),31-38(1998).
18.Herrmann,F.J.,&Hennenfent,G.Non-parametricseismicdatarecoverywithcurvelet
frames.GeophysicalJournalInternational,173(1),233-248(2008).
19.Trad,D.,Ulrych,T.,&Sacchi,M.LatestviewsofthesparseRadontransform.Geophysics,68
(1),386-399(2003).
20.Hu,L.,etal.First-arrivalpickingwithaU-netconvolutionalnetwork.Geophysics,84(6),U45-
U57(2019).
21.Mandelli,S.,etal.Seismicdatainterpolationthroughconvolutionalautoencoder.SEG
InternationalExpositionandAnnualMeeting(2018).
22.Yang,F.,&Ma,J.Deep-learninginversion:Anext-generationseismicvelocitymodelbuilding
method.Geophysics,84(4),R583-R599(2019).
23.Bergen,K.J.,Johnson,P.A.,deHoop,M.V.,&Beroza,G.C.Machinelearningfordata-driven
discoveryinsolidEarthgeoscience.Science,363(6433),eaau0323(2019).
24.Naveed,H.,etal.Acomprehensiveoverviewoflargelanguagemodels.Preprintat
https://doi.org/10.48550/arXiv.2307.06435(2023).
25.Zhao,W.X.,etal.Asurveyoflargelanguagemodels.Preprintat
https://doi.org/10.48550/arXiv.2303.18223(2023).
26.Brown,T.,etal.Languagemodelsarefew-shotlearners.AdvancesinNeuralInformation
ProcessingSystems,33,1877-1901(2020).
27.Vaswani,A.,etal.Attentionisallyouneed.AdvancesinNeuralInformationProcessing
Systems,30(2017).
28.Christiano,P.F.,etal.Deepreinforcementlearningfromhumanpreferences.Advancesin
NeuralInformationProcessingSystems,30(2017).
29.Chowdhery,A.,etal.Palm:Scalinglanguagemodelingwithpathways.JournalofMachine
LearningResearch,24(240),1-113(2023).
30.Touvron,H.,etal.Llama2:Openfoundationandfine-tunedchatmodels.Preprintat
https://doi.org/10.48550/arXiv.2307.09288(2023)
31.Anthropic.IntroducingClaude.AnthropicBloghttps://www.anthropic.com/news/introducing-
claude(2024).
32.Thoppilan,R.,etal.LaMDA:Languagemodelsfordialogapplications.Preprintat
https://doi.org/10.48550/10.48550/arXiv.2201.08239(2022).
33.Zeng,A.,etal.GLM-130b:Anopenbilingualpre-trainedmodel.InternationalConferenceon
LearningRepresentations(2023).
34.Zhang,S.,etal.,OPT:Openpre-trainedtransformerlanguagemodels.”Preprintat
https://doi.org/10.48550/arXiv.2205.01068(2022).
35.Hoffmann,J.,etal.Anempiricalanalysisofcompute-optimallargelanguagemodels.Advances
inNeuralInformationProcessingSystems,35,30016-30030(2022).
36.Zhang,Y.,Wei,C.,Wu,S.,He,Z.,&Yu,W.(2023).GeoGPT:understandingandprocessing
geospatialtasksthroughanautonomousGPT.arXivpreprintarXiv:2307.07930.
37.Kuckreja,K.,etal.Geochat:Groundedlargevision-languagemodelforremote
sensing.ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition
(2024).
38.Bran,A.M.,etal.ChemCrow:Augmentinglarge-languagemodelswithchemistry
tools.NeurIPS2023AIforScienceWorkshop(2023).
39.Li,Y.,Wang,H.,&Luo,Y.Acomparisonofpre-trainedvision-and-languagemodelsfor
multimodalrepresentationlearningacrossmedicalimagesandreports.2020IEEEInternational
ConferenceonBioinformaticsandBiomedicine(2020).
40.Wang,Z.,etal.MedCLIP:Contrastivelearningfromunpairedmedicalimagesand
text.Proceedingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,
3876-3887(2022).
41.Qiu,J.,etal.LargeAImodelsinhealthinformatics:Applications,challenges,andthe
future.IEEEJournalofBiomedicalandHealthInformatics,27(12),6074-6087(2023).
42.Dosovitskiy,A.,etal.Animageisworth16x16words:Transformersforimagerecognitionat
scale.InternationalConferenceonLearningRepresentations(2021).
43.Yu,F.,etal.Scalinguptoexcellence:practicingmodelscalingforphoto-realisticimage
restorationintheWild.Preprintathttps://doi.org/10.48550/2401.13627(2024).
44.Radford,A.,etal.Learningtransferablevisualmodelsfromnaturallanguage
supervision.Proceedingsofthe38thInternationalConferenceonMachineLearning,139,8748-8763
(2021).
45.Ramesh,A.,etal.Hierarchicaltext-conditionalimagegenerationwithcliplatents.Preprintas
https://doi.org/10.48550/arXiv.2204.06125(2022).
46.Saharia,C.,etal.Photorealistictext-to-imagediffusionmodelswithdeeplanguage
understanding.AdvancesinNeuralInformationProcessingSystems,35,36479-36494(2022).
47.Rombach,R.,etal.High-resolutionimagesynthesiswithlatentdiffusionmodels.Proceedingsof
theIEEE/CVFConferenceonComputerVisionandPatternRecognition(2021).
48.Wang,J.,etal.Reviewoflargevisionmodelsandvisualpromptengineering.Meta-Radiology,
100047(2023).
49.Bai,Y.,etal.Sequentialmodelingenablesscalablelearningforlargevisionmodels.Preprintat
https://doi.org/10.48550/arXiv.2312.00785(2023).
50.Guo,J.,etal.Data-efficientlargevisionmodelsthroughsequentialautoregression.Preprintat
https://doi.org/10.48550/arXiv.2402.04841(2024).
51.Tiu,E.,etal.Expert-leveldetectionofpathologiesfromunannotatedchestX-rayimagesviaself-
supervisedlearning.NatureBiomedicalEngineering,6(12),1399-1406(2022).
52.Liang,P.P.,Zadeh,A.,&Morency,L.P.Foundations&trendsinmultimodalmachinelearning:
Principles,challenges,andopenquestions.ACMComputingSurveys,56(10),1-42(2024).
53.Alayrac,J.B.,etal.Flamingo:avisuallanguagemodelforfew-shotlearning.Advancesin
NeuralInformationProcessingSystems,35,23716-23736(2022).
54.Girdhar,R.,etal.Imagebind:Oneembeddingspacetobindthemall.InProceedingsofthe
IEEE/CVFConferenceonComputerVisionandPatternRecognition,15180-15190(2023).
55.Ramesh,A.,etal.Zero-shottext-to-imagegeneration.InternationalConferenceonMachine
Learning,8821-8831(2021).
56.Saharia,C.,etal.Photorealistictext-to-imagediffusionmodelswithdeeplanguage
understanding.Advancesinneuralinformationprocessingsystems,35,36479-36494(2022).
57.Li,J.,etal.Blip-2:Bootstrappinglanguage-imagepre-trainingwithfrozenimageencodersand
largelanguagemodels.InInternationalConferenceonMachineLearning,19730-19742(2023).
58.Guo,Z.,Wu,X.,Liang,L.,Sheng,H.,Chen,N.,&Bi,Z.(2024).Cross-DomainFoundation
ModelAdaptation:PioneeringComputerVisionModelsforGeophysicalDataAnalysis.arXiv
preprintarXiv:2408.12396.
59.Han,L.,Wu,X.,Hu,Z.,Li,J.,&Fang,H.(2024).MAMCL:Multi-attributesMasking
ContrastiveLearningforexplainableseismicfaciesanalysis.Computers&Geosciences,193,
105731.
60.Zheng,Q.,&Zhang,D.(2022).RockGPT:reconstructingthree-dimensionaldigitalrocksfrom
singletwo-dimensionalslicewithdeeplearning.ComputationalGeosciences,26(3),677-696.
61.KumarA.VisionTransformerBasedFoundationModelforOilReservoirForecasting[C]//85th
EAGEAnnualConference&Exhibition(includingtheWorkshopProgramme).European
AssociationofGeoscientists&Engineers,2024,2024(1):1-5.
62.Zhang,H.,Xu,J.J.,Cui,H.W.,Li,L.,Yang,Y.,Tang,C.S.,&Boers,N.(2023).When
geosciencemeetsfoundationmodels:Towardsgeneralgeoscienceartificialintelligencesystem.
arXivpreprintarXiv:2309.06799.
63.Hadid,A.,Chakraborty,T.,&Busby,D.(2024).WhengeosciencemeetsgenerativeAIandlarge
languagemodels:Foundations,trends,andfuturechallenges.ExpertSystems,e13654.
64.DATA,M.(2024).Multimodalartificialintelligencefoundationmodels:Unleashingthepower
ofremotesensingbigdatainearthobservation.Innovation,2(1),100055.
65.Lu,S.,Guo,J.,Zimmer-Dauphinee,J.R.,Nieusma,J.M.,Wang,X.,VanValkenburgh,P.,...&
Huo,Y.(2024).Aifoundationmodelsinremotesensing:Asurvey.arXivpreprintarXiv:2408.03464.
66.Jiao,L.,Huang,Z.,Lu,X.,Liu,X.,Yang,Y.,Zhao,J.,...&Feng,J.(2023).Brain-inspired
remotesensingfoundationmodelsandopenproblems:Acomprehensivesurvey.IEEEJournalof
SelectedTopicsinAppliedEarthObservationsandRemoteSensing.
67.LIUHe,RENYili,LIXin,DENGYue,WANGYongtao,CAOQianwen,DUJinyang,LIN
Zhiwei,WANGWenjie.Researchstatusandapplicationofartificialintelligencelargemodelsinthe
oilandgasindustry[J].PetroleumExplorationandDevelopment,2024,51(4):910-923.
https://doi.org/10.11698/PED.20240254
68.Si,X.,Wu,X.,Sheng,H.,Zhu,J.,&Li,Z.(2024).SeisCLIP:Aseismologyfoundationmodel
pre-trainedbymulti-modaldataformulti-purposeseismicfeatureextraction.IEEETransactionson
GeoscienceandRemoteSensing.
69.Liu,T.,Münchmeyer,J.,Laurenti,L.,Marone,C.,deHoop,M.V.,&Dokmanić,I.(2024).
SeisLM:aFoundationModelforSeismicWaveforms.arXivpreprintarXiv:2410.15765.
70.Zhu,X.X.,Xiong,Z.,Wang,Y.,Stewart,A.J.,Heidler,K.,Wang,Y.,...&Shi,Y.(2024).On
theFoundationsofEarthandClimateFoundationModels.arXivpreprintarXiv:2405.04285.
71.Zhang,L.,Cui,H.,Song,Y.,Li,C.,Yuan,B.,&Lu,M.(2024).OntheOpportunitiesof(Re)-
ExploringAtmosphericSciencebyFoundationModels:ACaseStudy.arXivpreprint
arXiv:2407.17842.
72.Zheng,Z.,Chen,Y.,Zeng,H.,Vu,T.A.,Hua,B.S.,&Yeung,S.K.(2025).MarineInst:A
FoundationModelforMarineImageAnalysiswithInstanceVisualDescription.InEuropean
ConferenceonComputerVision(pp.239-257).Springer,Cham.
73.Bi,Z.,Zhang,N.,Xue,Y.,Ou,Y.,Ji,D.,Zheng,G.,&Chen,H.(2023).Oceangpt:Alarge
languagemodelforoceansciencetasks.arXivpreprintarXiv:2310.02031.
74.Chen,K.,Liu,C.,Chen,H.,Zhang,H.,Li,W.,Zou,Z.,&Shi,Z.(2024).RSPrompter:Learning
topromptforremotesensinginstancesegmentationbasedonvisualfoundationmodel.IEEE
TransactionsonGeoscienceandRemoteSensing.
75.Sultan,R.I.,Li,C.,Zhu,H.,Khanduri,P.,Brocanelli,M.,&Zhu,D.(2023).GeoSAM:Fine-
tuningSAMwithsparseanddensevisualpromptingforautomatedsegmentationofmobility
infrastructure.arXivpreprintarXiv:2311.11319.
76.Huang,Z.,etal.STU-Net:Scalableandtransferablemedicalimagesegmentationmodels
empoweredbylarge-scalesupervisedpre-training.Preprintathttps://doi.org/10.48550/2304.06716
(2023).
77.Wei,J.,Wang,X.,Schuurmans,D.,Bosma,M.,Xia,F.,Chi,E.,...&Zhou,D.(2022).Chain-of-
thoughtpromptingelicitsreasoninginlargelanguagemodels.Advancesinneuralinformation
processingsystems,35,24824-24837.
78.Lu,M.Y.,Chen,B.,Williamson,D.F.,Chen,R.J.,Zhao,M.,Chow,A.K.,...&Mahmood,F.
(2024).AmultimodalgenerativeAIcopilotforhumanpathology.Nature,634(8033),466-473.
79.Liang,P.P.,Zadeh,A.,&Morency,L.P.(2024).Foundations&trendsinmultimodalmachine
learning:Principles,challenges,andopenquestions.ACMComputingSurveys,56(10),1-42.
80.Christie,G.,etal.Functionalmapoftheworld.ProceedingsoftheIEEEConferenceon
ComputerVisionandPatternRecognition,6172-6180(2018).
81.Bastani,F.,etal.SatlasPretrain:Alarge-scaledatasetforremotesensingimageunderstanding.
ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision,16772-16782(2023).
82.Zhan,Y.,Xiong,Z.,&Yuan,Y.RSVG:Exploringdataandmodelsforvisualgroundingon
remotesensingdata.IEEETransactionsonGeoscienceandRemoteSensing,61,1-13(2023).
83.Liu,H.,etal.Visualinstructiontuning.AdvancesinNeuralInformationProcessingSystems,36
(2024).
84.Ross,Z.E.,Meier,M.A.,&Hauksson,E.Pwavearrivalpickingandfirst-motionpolarity
determinationwithdeeplearning.JournalofGeophysicalResearch:SolidEarth,123(6):5120-5129
(2018).
85.Pardo,E.,Garfias,C.,&Malpica,N.SeismicphasepickingusingconvolutionalnetworksIEEE
TransactionsonGeoscienceandRemoteSensing,57(9),7086-7092(2019).
86.Mousavi,S.M.etal.Earthquaketransformer–anattentivedeeplearningmodelforsimultaneous
earthquakedetectionandphasepicking.NatureCommunications,11(1),3952(2020).
87.Zhao,M.,etal.DiTingmotion:Adeeplearningfirstmotionpolarityclassifieranditsapplication
tofocalmechanisminversion.FrontierinEarthScience,11,1103914(2023).
88.Yano,K.,etal.Graph-partitioningbasedconvolutionalneuralnetworkforearthquakedetection
usingaseismicarray.JournalofGeophysicalResearch:SolidEarth,126(5),e2020JB020269(2021).
89.Yang,S.,Hu,J.,Zhang,H.,&Liu,G.Simultaneousearthquakedetectiononmultiplestationsvia
aconvolutionalneuralnetwork.SeismologicalSocietyofAmerica,92(1),246-260(2021).
90.DeVries,P.M.,etal.Deeplearningofaftershockpatternsfollowinglargeearthquakes.Nature,
560(7720),632-634(2018).
91.Zhang,X.,etal.LocatinginducedearthquakeswithanetworkofseismicstationsinOklahoma
viaadeeplearningmethod.Scientificreports,10(1),1941(2020).
92.Rouet-Leduc,B.,etal.Machinelearningpredictslaboratoryearthquakes.GeophysicalResearch
Letters,44(18),9276-9282(2017).
93.Li,Z.,Kovachki,N.,Azizzadenesheli,K.,Liu,B.,Bhattacharya,K.,Stuart,A.,&Anandkumar,
A.(2020).Fourierneuraloperatorforparametricpartialdifferentialequations.arXivpreprint
arXiv:2010.08895.
94.Lehmann,F.,Gatti,F.,Bertin,M.,&Clouteau,D.(2023).Fourierneuraloperatorsurrogate
modeltopredict3Dseismicwavespropagation.arXivpreprintarXiv:2304.10242.
95.Yang,Y.,Gao,A.F.,Azizzadenesheli,K.,Clayton,R.W.,&Ross,Z.E.(2023).Rapidseismic
waveformmodelingandinversionwithneuraloperators.IEEETransactionsonGeoscienceand
RemoteSensing,61,1-12.
96.Johnson,P.A.,etal.Laboratoryearthquakeforecasting:Amachinelearningcompetition.
ProceedingsoftheNationalAcademyofSciences,118(5),e2011362118(2021).
97.Borate,P.,etal.Usingaphysics-informedneuralnetworkandfaultzoneacousticmonitoringto
predictlabearthquakes.NatureCommunications,14(1),3693(2023).
98.Si,X.,Wu,X.,Sheng,H.,Zhu,J.,&Li,Z.SeisCLIP:Aseismologyfoundationmodelpre-
trainedbymultimodaldataformulti-purposeseismicfeatureextraction.IEEETransactionson
GeoscienceandRemoteSensing,62(2024).
99.Li,S.,etal.SeisT:Afoundationdeeplearningmodelforearthquakemonitoringtasks.IEEE
TransactionsonGeoscienceandRemoteSensing,62(2024).
100.Zhao,M.,Xiao,Z.,Chen,S.,&Fang,L.(2023).DiTing:Alarge-scaleChineseseismic
benchmarkdatasetforartificialintelligenceinseismology.EarthquakeScience,36(2),84-94.
101.Ni,Y.,Hutko,A.,Skene,F.,Denolle,M.,Malone,S.,Bodin,P.,...&Wright,A.(2023).
CuratedPacificNorthwestAI-readyseismicdataset.
102.Ritchie,H.,etal.Implementationofthesemi-Lagrangianmethodinahigh-resolutionversionof
theECMWFforecastmodel.MonthlyWeatherReview,123(2),489-514(1995).
103.Molteni,F.,Buizza,R.,Palmer,T.N.,&Petroliagis,T.TheECMWFensembleprediction
system:Methodologyandvalidation.QuarterlyJournaloftheRoyalMeteorologicalSociety,122
(529),73-119(1996).
104.Weyn,J.A.,Durran,D.R.,&Caruana,R.Canmachineslearntopredictweather?Usingdeep
learningtopredictgridded500-hPageopotentialheightfromhistoricalweatherdata.Journalof
AdvancesinModelingEarthSystems,11(8),2680-2693(2019).
105.Rasp,S.,etal.WeatherBench:abenchmarkdatasetfordata-drivenweatherforecasting.Journal
ofAdvancesinModelingEarthSystems,12(11),e2020MS002203(2020).
106.Zhang,Y.,etal.SkilfulnowcastingofextremeprecipitationwithNowcastNet.Nature,619,
526-532(2023).
107.Bi,K.,etal.Accuratemedium-rangeglobalweatherforecastingwith3Dneural
networks.Nature,619,533-538(2023).
108.Bi,Z.,etal.OceanGPT:Alargelanguagemodelforoceansciencetasks.Preprintat
https://doi.org/10.48550/arXiv.2310.02031(2024).
109.Xiong,W.,etal.AI-GOMS:Large-AIdrivenglobaloceanmodelingsystem.Preprintat
https://doi.org/10.48550/2308.03152(2023).
110.Sheng,H.,etal.SeismicFoundationModel(SFM):anewgenerationdeeplearningmodelin
geophysics.Preprintathttps://doi.org/10.48550/arXiv.2309.02791(2023).
111.St-Charles,P.L.,etal.Amulti-surveydatasetandbenchmarkforfirstbreakpickinginhard
rockseismicexploration.Proceedingsofthe2021NeurIPSWorkshoponMachineLearningforthe
PhysicalSciences(2021).
112.Houlsby,N.,etal.Parameter-efficienttransferlearningforNLP.Proceedingsofthe36th
InternationalConferenceonMachineLearning,97,2790-2799(2019).
113.Hu,E.J.,etal.Lora:Low-rankadaptationoflargelanguagemodels.InternationalConference
onLearningRepresentations(2021).
114.Chen,T.,etal.SAM-Adapter:Adaptingsegmentanythinginunderperformed
scenes.ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision,3367-3375
(2023).
115.Wang,D.,etal.Samrs:Scaling-upremotesensingsegmentationdatasetwithsegmentanything
model.AdvancesinNeuralInformationProcessingSystems,36(2024).
116.He,K.,etal.Maskedautoencodersarescalablevisionlearners.ProceedingsoftheIEEE/CVF
ConferenceonComputerVisionandPatternRecognition(2022).
117.Song,Y.,&Ermon,S.Generativemodelingbyestimatinggradientsofthedata
distribution.AdvancesinNeuralInformationProcessingSystems,32(2019).
118.Ho,J.,Jain,A.,&Abbeel,P.Denoisingdiffusionprobabilisticmodels.AdvancesinNeural
InformationProcessingSystems,33,6840-6851(2020).
119.Goodfellow,I.,etal.Generativeadversarialnetworks.CommunicationsoftheACM,63(11),
139-144(2020).
120.Lin,X.,etal.DiffBIR:Towardsblindimagerestorationwithgenerativediffusion
prior.Preprintathttps://doi.org/10.48550/arXiv.2308.15070(2023).
121.Wang,J.,Yue,Z.,Zhou,S.,Chan,K.C.,&Loy,C.C.Exploitingdiffusionpriorforreal-world
imagesuper-resolution.Preprintathttps://doi.org/10.48550/arXiv.2305.07015(2023).
122.Araya-Polo,M.,Jennings,J.,Adler,A.,&Dahlke,T.Deep-learningtomography.TheLeading
Edge,37(1),58-66(2018).
123.Sun,P.,Yang,F.,Liang,H.,&Ma,J.Full-waveforminversionusingalearned
regularization.IEEETransactionsonGeoscienceandRemoteSensing,61(2023).
124.Ovcharenko,O.,Kazei,V.,Kalita,M.,Peter,D.,&Alkhalifah,T.Deeplearningforlow-
frequencyextrapolationfrommultioffsetseismicdata.Geophysics,84(6),R989-R1001(2019).
125.Ye,Z.,etal.PDEformer:Towardsafoundationmodelforone-dimensionalpartialdifferential
equations.”Preprintathttps://doi.org/10.48550/arXiv.2402.12652(2024).
126.Deng,C.,etal.K2:Afoundationlanguagemodelforgeoscienceknowledgeunderstandingand
utilization.Proceedingsofthe17thACMInternationalConferenceonWebSearchandDataMining
(2024).
127.Lin,Z.,etal.GeoGalactica:Ascientificlargelanguagemodelingeoscience.Preprintat
https://doi.org/10.18550/arXiv.2401.00434(2023).
128.Taylor,R.,etal.Galactica:Alargelanguagemodelforscience.Preprintat
https://doi.org/10.48550/arXiv.2211.09085(2022).
129.Li,C.,etal.Llava-med:Trainingalargelanguage-and-visionassistantforbiomedicineinone
day.AdvancesinNeuralInformationProcessingSystems(2024).
130.Zhan,J.,Dai,J.,Ye,J.,Zhou,Y.,Zhang,D.,Liu,Z.,...&Qiu,X.(2024).Anygpt:Unified
multimodalllmwithdiscretesequencemodeling.arXivpreprintarXiv:2402.12226.
131.Chen,T.,Kornblith,S.,Norouzi,M.,&Hinton,G.(2020,November).Asimpleframeworkfor
contrastivelearningofvisualrepresentations.InInternationalconferenceonmachinelearning(pp.
1597-1607).PMLR.
132.He,K.,Fan,H.,Wu,Y.,Xie,S.,&Girshick,R.(2020).Momentumcontrastforunsupervised
visualrepresentationlearning.InProceedingsoftheIEEE/CVFconferenceoncomputervisionand
patternrecognition(pp.9729-9738).
133.Goodfellow,I.,Pouget-Abadie,J.,Mirza,M.,Xu,B.,Warde-Farley,D.,Ozair,S.,...&Bengio,
Y.(2014).Generativeadversarialnets.Advancesinneuralinformationprocessingsystems,27.
134.Ho,J.,Jain,A.,&Abbeel,P.(2020).Denoisingdiffusionprobabilisticmodels.Advancesin
neuralinformationprocessingsystems,33,6840-6851.
135.Liu,Q.,&Ma,J.(2024).Generativeinterpolationviaadiffusionprobabilistic
model.Geophysics,89(1),V65-V85.
136.Rombach,R.,Blattmann,A.,Lorenz,D.,Esser,P.,&Ommer,B.(2022).High-resolutionimage
synthesiswithlatentdiffusionmodels.InProceedingsoftheIEEE/CVFconferenceoncomputer
visionandpatternrecognition(pp.10684-10695).
137.Devlin,J.(2018).Bert:Pre-trainingofdeepbidirectionaltransformersforlanguage
understanding.arXivpreprintarXiv:1810.04805.
138.Marfurt,K.J.(1984).Accuracyoffinite-differenceandfinite-elementmodelingofthescalar
andelasticwaveequations.Geophysics,49(5),533-549.
139.Gavrilyuk,K.,Sanford,R.,Javan,M.,&Snoek,C.G.(2020).Actor-transformersforgroup
activityrecognition.InProceedingsoftheIEEE/CVFconferenceoncomputervisionandpattern
recognition(pp.839-848).
140.Shi,B.,Hsu,W.N.,Lakhotia,K.,&Mohamed,A.(2022).Learningaudio-visualspeech
representationbymaskedmultimodalclusterprediction.arXivpreprintarXiv:2201.02184.
141.Li,R.,Yang,S.,Ross,D.A.,&Kanazawa,A.(2021).Aichoreographer:Musicconditioned3d
dancegenerationwithaist++.InProceedingsoftheIEEE/CVFInternationalConferenceon
ComputerVision(pp.13401-13412).
142.Lin,J.,Yang,A.,Zhang,Y.,Liu,J.,Zhou,J.,&Yang,H.(2020).Interbert:Vision-and-
languageinteractionformulti-modalpretraining.arXivpreprintarXiv:2003.13198.
143.Lu,J.,Batra,D.,Parikh,D.,&Lee,S.(2019).Vilbert:Pretrainingtask-agnosticvisiolinguistic
representationsforvision-and-languagetasks.Advancesinneuralinformationprocessingsystems,
32.
144.Zhan,X.,Wu,Y.,Dong,X.,Wei,Y.,Lu,M.,Zhang,Y.,...&Liang,X.(2021).Product1m:
Towardsweaklysupervisedinstance-levelproductretrievalviacross-modalpretraining.In
ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision(pp.11782-11791).
145.Zhu,B.,Lin,B.,Ning,M.,Yan,Y.,Cui,J.,Wang,H.,...&Yuan,L.(2023).Languagebind:
Extendingvideo-languagepretrainington-modalitybylanguage-basedsemanticalignment.arXiv
preprintarXiv:2310.01852.
146.Zhang,D.,Li,S.,Zhang,X.,Zhan,J.,Wang,P.,Zhou,Y.,&Qiu,X.(2023).Speechgpt:
Empoweringlargelanguagemodelswithintrinsiccross-modalconversationalabilities.arXiv
preprintarXiv:2305.11000.
147.Zhang,H.,Li,X.,&Bing,L.(2023).Video-llama:Aninstruction-tunedaudio-visuallanguage
modelforvideounderstanding.arXivpreprintarXiv:2306.02858.
148.Carion,N.,Massa,F.,Synnaeve,G.,Usunier,N.,Kirillov,A.,&Zagoruyko,S.(2020,August).
End-to-endobjectdetectionwithtransformers.InEuropeanconferenceoncomputervision(pp.213-
229).Cham:SpringerInternationalPublishing.
149.Tsai,Y.H.H.,Bai,S.,Liang,P.P.,Kolter,J.Z.,Morency,L.P.,&Salakhutdinov,R.(2019,
July).Multimodaltransformerforunalignedmultimodallanguagesequences.InProceedingsofthe
conference.Associationforcomputationallinguistics.Meeting(Vol.2019,p.6558).NIHPublic
Access.
150.Murahari,V.,Batra,D.,Parikh,D.,&Das,A.(2020,August).Large-scalepretrainingfor
visualdialog:Asimplestate-of-the-artbaseline.InEuropeanConferenceonComputerVision(pp.
336-352).Cham:SpringerInternationalPublishing.
151.Swetha,S.,Yang,J.,Neiman,T.,Rizve,M.N.,Tran,S.,Yao,B.,...&Shah,M.(2024).X-
Former:UnifyingContrastiveandReconstructionLearningforMLLMs.arXivpreprint
arXiv:2407.13851.
152.Su,Y.,Lan,T.,Li,H.,Xu,J.,Wang,Y.,&Cai,D.(2023).Pandagpt:Onemodeltoinstruction-
followthemall.arXivpreprintarXiv:2305.16355.
153.Pi,R.,Gao,J.,Diao,S.,Pan,R.,Dong,H.,Zhang,J.,...&Zhang,T.(2023).Detgpt:Detect
whatyouneedviareasoning.arXivpreprintarXiv:2305.14167.
154.Chen,H.,Tao,R.,Zhang,H.,Wang,Y.,Li,X.,Ye,W.,...&Savvides,M.(2024).Conv-
adapter:Exploringparameterefficienttransferlearningforconvnets.InProceedingsofthe
IEEE/CVFConferenceonComputerVisionandPatternRecognition(pp.1551-1561).
155.Lester,B.,Al-Rfou,R.,&Constant,N.(2021).Thepowerofscaleforparameter-efficient
prompttuning.arXivpreprintarXiv:2104.08691.
156.Petrov,A.,Torr,P.H.,&Bibi,A.(2023).Whendopromptingandprefix-tuningwork?atheory
ofcapabilitiesandlimitations.arXivpreprintarXiv:2310.19698.
157.Li,X.L.,&Liang,P.(2021).Prefix-tuning:Optimizingcontinuouspromptsforgeneration.
arXivpreprintarXiv:2101.00190.
158.Zaken,E.B.,Ravfogel,S.,&Goldberg,Y.(2021).Bitfit:Simpleparameter-efficientfine-
tuningfortransformer-basedmaskedlanguage-models.arXivpreprintarXiv:2106.10199.
159.Fu,C.L.,Chen,Z.C.,Lee,Y.R.,&Lee,H.Y.(2022).Adapterbias:Parameter-efficienttoken-
dependentrepresentationshiftforadaptersinnlptasks.arXivpreprintarXiv:2205.00305.
160.Gheini,M.,Ren,X.,&May,J.(2021).Cross-attentionisallyouneed:Adaptingpretrained
transformersformachinetranslation.arXivpreprintarXiv:2104.08771.
161.Ansell,A.,Ponti,E.M.,Korhonen,A.,&Vulić,I.(2021).Composablesparsefine-tuningfor
cross-lingualtransfer.arXivpreprintarXiv:2110.07560.
162.Hayou,S.,Ghosh,N.,&Yu,B.(2024).Lora+:Efficientlowrankadaptationoflargemodels.
arXivpreprintarXiv:2402.12354.
163.Yang,A.X.,Robeyns,M.,Wang,X.,&Aitchison,L.(2023).Bayesianlow-rankadaptationfor
largelanguagemodels.arXivpreprintarXiv:2308.13111.
164.Lin,Y.,Ma,X.,Chu,X.,Jin,Y.,Yang,Z.,Wang,Y.,&Mei,H.(2024).Loradropoutasa
sparsityregularizerforoverfittingcontrol.arXivpreprintarXiv:2404.09610.
165.He,J.,Zhou,C.,Ma,X.,Berg-Kirkpatrick,T.,&Neubig,G.(2021).Towardsaunifiedviewof
parameter-efficienttransferlearning.arXivpreprintarXiv:2110.04366.
166.Hu,Z.,Wang,L.,Lan,Y.,Xu,W.,Lim,E.P.,Bing,L.,...&Lee,R.K.W.(2023).Llm-
adapters:Anadapterfamilyforparameter-efficientfine-tuningoflargelanguagemodels.arXiv
preprintarXiv:2304.01933.
167.Karpathy,A.,&Fei-Fei,L.(2015).Deepvisual-semanticalignmentsforgeneratingimage
descriptions.InProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition(pp.
3128-3137).
168.Xu,P.,Zhu,X.,&Clifton,D.A.(2023).Multimodallearningwithtransformers:Asurvey.
IEEETransactionsonPatternAnalysisandMachineIntelligence,45(10),12113-12132.
169.Liu,X.,Zhang,F.,Hou,Z.,Mian,L.,Wang,Z.,Zhang,J.,&Tang,J.(2021).Self-supervised
learning:Generativeorcontrastive.IEEEtransactionsonknowledgeanddataengineering,35(1),
857-876.
