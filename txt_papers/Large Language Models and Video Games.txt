Large Language Models and Video Games: A Preliminary Scoping Review
PENNY SWEETSER, The Australian National University, Australia
Large language models (LLMs) hold interesting potential for the design, development, and research of video games. Building on the
decades of prior research on generative AI in games, many researchers have sped to investigate the power and potential of LLMs for
games. Given the recent spike in LLM-related research in games, there is already a wealth of relevant research to survey. In order to
capture a snapshot of the state of LLM research in games, and to help lay the foundation for future work, we carried out an initial
scoping review of relevant papers published so far. In this paper, we review 76 papers published between 2022 to early 2024 on LLMs
and video games, with key focus areas in game AI, game development, narrative, and game research and reviews. Our paper provides
an early state of the field and lays the groundwork for future research and reviews on this topic.
CCS Concepts: • Software and its engineering → Interactive games; • Computing methodologies → Natural language
generation; • Applied computing → Computer games.
Additional Key Words and Phrases: large language models, LLMs, games, videogames, GPT
ACM Reference Format:
Penny Sweetser. 2024. Large Language Models and Video Games: A Preliminary Scoping Review. 1, 1 (March 2024), 12 pages.
https://doi.org/10.1145/nnnnnnn.nnnnnnn
1 INTRODUCTION
Since OpenAI’s release of ChatGPT in late 2022, awareness and usage of Large Language Models (LLMs) has surged in
research, development, and the general population across a broad spectrum of domains. LLMs are powerful tools for
language processing and prediction, pre-trained on vast collections of natural language, and capable of performing
diverse language analysis and generation tasks [23 ]. The release of ChatGPT, along with the many other available LLMs
(e.g., GPT-4, LLaMa, Codex, BERT) has opened new doors to research and development potential, which has seen a
recent increase in related research. Like many fields, LLMs hold interesting possibilities for video games, which has
prompted many researchers to hasten to investigate the potential for applying LLMs to various aspects of video game
research and development. Although the concept of generative AI is not new to video games, with decades of prior
work in AI-powered generation of game content [ 26, 46 ], LLMs have the potential to revolutionise generation and
co-creation of video game content, along with game development tools and processes, and games research approaches.
As research and development of LLMs and games is occurring and evolving quickly, it is difficult to capture a full picture
of how LLMs are being used in games research. The aim of this paper is to provide a preliminary scoping review of
LLMs and video games, surveying the related research conducted between 2020 and 2023. We aim to identify the ways
in which researchers have been exploring the use of LLMs for game development and research to date. To identify
the relevant papers, we conducted a Google Scholar search for papers published between 2020-2023 (and very early
2024). We identified 76 relevant papers from 2260 results returned in the search. Our review of the papers revealed
Author’s address: Penny Sweetser, penny.kyburz@anu.edu.au, The Australian National University, Canberra, Australia.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party
components of this work must be honored. For all other uses, contact the owner/author(s).
© 2024 Copyright held by the owner/author(s).
Manuscript submitted to ACM
Manuscript submitted to ACM 1
arXiv:2403.02613v1 [cs.HC] 5 Mar 20246 Penny Sweetser
approach for users to craft controllable, realistic, and fully-realised 3D characters within 2 minutes, showing potential
for integration into a game art pipeline.
The papers on serious games and game-based learning related to using LLMs to support educators in developing
games [ 4 , 28 , 70 , 83 ], as well as more specifically to role-playing game design [ 56 ], board game design [28 , 70 ], and level
[ 31] and game generation [ 13 ] for serious games. A common goal of these papers was to support time-poor teachers
in developing educational games for their classrooms in an expedited manner and without the need for expertise
in game development [ 28, 70, 83]. LLMs were used to support educators with brainstorming [28 ], choosing a game
[ 70 ], personalising the game for constructive alignment and inclusion [ 70 ], suggesting game themes and mechanisms
aligned with curriculum and learning goals [ 28 ], providing templates or exemplars of game components [28 ], tailoring
strategies to address specific learning challenges [83], supporting teachers in crafting personalised learning blueprints
[ 83], and offering feedback on game prototypes and identifying areas for improvement [ 70]. One paper also explored
the creation of games as a learning mechanisms in combination with playing the game, which was found to have
“double impact” (first through design, then through play) [56 ]. Overall, researchers found that generative AI offers great
potential for supporting and enhancing (rather than replacing) designers and educators in the creation of serious games
and game-based learning education [13, 28 , 70 ]. They also found that generative AI can be an effective design tool for
diverse populations (e.g., educators, students, domain experts) [31].
Apart from the previously discussed papers on design of serious games and game-based learning, the game design
papers focused on use of LLMs for game idea generation [34 ] and game mechanic design [27 ]. The idea generation
paper [34 ] presented a collaborative design framework that aimed to simulate the typical human design process. As
part of this framework, LLMs were used for the recombination and variation of ideas. The game mechanic paper [ 27 ]
used an LLM for an element synthesis game, where players can combine elements to create new content based on
physical and chemical properties of the combined elements, conceptual association, combination principles, and other
logical reasoning rules. The researchers found that their LLM-based framework was effective in simulating element
synthesis in video games with high freedom, high logic, repeatable playability, and more content. However, they noted
that the inherent uncertainty in text generated by LLMs can have adverse effects on game mechanics.
The role-playing game (RPG) papers [ 20 , 56 , 87 ] involved using LLMs to design RPGs [ 56 ], to aid in playing RPGs
online [87 ], and act as game masters in RPGs [ 20 ]. As previously discussed in relation to serious games, using LLMs
to design RPGs was found to be an effective learning tool for children, particularly paired with the children also
playing the games they designed [ 56 ]. For aiding people to play RPGs (in this case Dungeons and Dragons, or DnD)
online, researchers [87] collected a dataset with 25,000 unique DnD sessions from real games on Discord that used the
Avrae bot, including language, game commands, and underlying game state information. They found that their dataset
(FIREBALL) improved natural language generation according to both automated metrics and human judgements of
quality. For modelling RPG game masters (GMs), researchers [20 ] evaluated three LLMs (ChatGPT, Bard, OpenAssistant)
as out-of-the-box GMs. Considering the skills needed by a GM (creating and managing a fictional world, tracking
the game state, understanding the players’ actions), they found that ChatGPT and Bard provided satisfying game
experiences, although they struggled with commonsense reasoning. They found that OpenAssistant was unable to
maintain the GM role during most tests.
2.3 Narrative, Story, and Dialogue
Most of the remaining papers (17/76, 22.4%) related to the theme of Narrative, Story, and Dialogue. The papers within
this theme related to dialogue or conversation generation (11/17) [ 2, 3, 5 , 16, 32 , 35 , 43, 45 , 49 , 62 , 75], story generation
Manuscript submitted to ACMLarge Language Models and Video Games: A Preliminary Scoping Review 7
and interactive story (6/17) [2, 22 , 32 , 61 , 68 , 69 , 82 ], and quest generation (2/17) [ 5, 72]. Two papers related to both
dialogue and story generation [2 , 32 ] and one paper to both dialogue and quest generation [5 ]. Two papers considered
both NPC dialogue and NPC actions/tasks [49, 75].
The papers on dialogue generation mostly focused on non-player characters (NPCs) in games. However, there was
one case where the dialogue was for an online streamer commentating matches in a fighting game (DareFightingICE)
[ 45] and another where NPCs from a game were interacting with players in an online Discord community external
to the game [ 62 ]. Papers on dialogue generation focused on different dimensions of dialogue and NPCs, including
context-awareness and in-context dialogue [ 5 , 16 , 43], style and personality [35 , 43 ], and story-focused dialogue [ 2, 32 ].
Most papers performed an evaluation of their systems with human players or game developers. The reported results
were mixed, depending on the focus of the papers and the criteria for success. Some researchers reported on the difficulty
of using LLMs to generate NPC dialogue [2] and evaluator preferences for game designer generated text compared
to LLM-generated text [3]. Others reported that the LLM-generated text enhanced the player experience generally
[5, 49 , 62 ] or within specific conditions (e.g., with context-aware NPCs [ 16 ]). Some papers reported on the success of
the approach via other performance metrics [32, 35, 43, 75].
The papers on story and quest generation investigated different aspects of game story endings [22 , 68, 69 ], the use of
LLMs for generating interactive story games [61 , 82 ], and quest description generation [ 5, 35 ]. Papers focusing on story
endings explored the valence (positive/neutral/negative) [ 68 ] and bias of the generated endings [69 ] and the impact
of generating stories with/without a prompted ending (along with inspiration keywords) [ 22]. The interactive story
generation papers studied players interacting with the commercial game AI Dungeon [ 82 ] and a custom game "1001
Nights" [ 61 ]. Research related to story endings found that generated stories were biased towards positive endings [69 ],
that models classified stories into uninstructed endings [68], and that more detail in prompts led to higher coherence
but less inspiration [22]. The interactive story researchers observed that player’s mental models shifted over the play
session from assuming a linear-branching narrative to one with open possibilities, impacting their motivations for
repeat engagement [ 82]. One paper proposed the term "AI-Native games" for games where generative AI is fundamental
to the game’s mechanics [ 61 ], also noting that inconsistency, incoherence, and AI-transparency are key challenges
in these games. One paper focused on quest generation found that LLM-generated quests approached hand-crafted
quests in terms of fluency, coherence, novelty, and creativity according to human evaluation [5 ]. Conversely, the other
quest generation paper found that only 1 in 5 generated quests were deemed acceptable by a human critic, with a large
variation in quality of the generated quests [35].
2.4 Game Research and Reviews
The remaining papers (7/76, 9.2%) related to LLMs for use in analysing or generating data about games, including
research data and game reviews. The papers in this theme used LLMs to analyse game reviews [33 , 74 ] and interviews
with video game players [17 ] and to generate synthetic data for hate speech in games [ 64 ], player responses to interview
questions [ 24 , 25 ], and utterances about video games [52 ]. Researchers found the LLMs to be effective for their research
purposes in analysis and generation, including dealing with the complex and highly abbreviated lexicons related
to games [ 64 ] and offering improvements in performance [74 ] and cost [ 24 , 25 ]. However, researchers also noted
some drawbacks, including variation in quality [24 ], lack of depth of content and flexibility [33 ], and potential for
crowd-sourced participant data to become unreliable [25].
Manuscript submitted to ACM8 Penny Sweetser
2.5 Recommendation
During our search process, we found an additional 9 papers [7 , 10, 38, 58 , 63 , 81 , 84– 86 ] that used game data sets as
part of broader LLM for recommendation (LLM4Rec) research. These papers did not fit the focus of our search, or of
this preliminary scoping review. However, we felt it was important to capture them in this paper, given their proximity
to the topic and their likely relevance to the games research community in future. Each of these papers made use of a
games dataset (Amazon 7/9, Steam 3/9), alongside other datasets (e.g., movies, books). The LLM4Rec papers focused on
performance of ranking-based recommendation [ 7, 84 ], sequential recommendation [ 81 ], instruction following and
tuning [85 ], interpretation and explanation [ 38 ], collaborative semantics [ 86], user alignment [58 ], intent-aware session
recommendation [63 ], and game features [ 10 ]. The LLM4Rec papers most frequently utilised LLaMA (4/9) and GPT
(4/9), whereas the games-focused papers overwhelmingly made use of GPT.
3 CONCLUSIONS
We reviewed 76 papers on LLMs and video games, published between 2022 to 2024, in order to provide a first snapshot
of the state of research on this topic and to lay the foundations for the rapidly moving ongoing and future work. We
designed our review to be narrowly focused on the application of LLMs to video games. As noted earlier, we included
papers that reported original research related to video games and LLMs. We excluded work that had not yet been
applied to games (but that could be applied to games in future). We also did not explicitly search for areas related
to games (e.g., gamification) or other types of generative models (e.g., image generation, multi-modal generation).
We found that research clustered around topics related to game AI (agents, RL, collaboration), game development
(content/game generation, serious games and game-based learning, game design, RPGs, bug detection), narrative
(conversation/story/quest generation), and game research and reviews (analysing/generating game data). Much of
the work reviewed constituted initial attempts at applying LLMs to different aspects of games. Researchers generally
reported positive results or indicated promising future work related to their application of LLMs to games. Others
reported success in combining LLMs with other approaches (e.g., RL) to outperform baselines. Some of the commonly
reported highlights included human interpretability, social behaviours and experiences, foundational skills (e.g., can
play games), and empowerment of non-developers to create games. Negatives included lack of logical reasoning ability
and unpredictability (e.g., in the context of generating content in live games). Given the explosion of interest around
LLMs, research will continue to move quickly on this topic. Our review aimed to provide a preliminary snapshot of the
state of the work on LLMs and games, to help researchers to understand the key directions and findings so far, and to
lay the foundation for future work. We expect that capturing the state of the field and keeping pace with new research
will be an ongoing challenge, but it is exciting to see where LLMs will take the field of games research and developmen